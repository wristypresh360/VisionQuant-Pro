"""VisionQuant Pro - å·¥ä¸šçº§ç²¾ç®€ç‰ˆ"""
import streamlit as st
import os, sys, glob, pandas as pd, numpy as np, mplfinance as mpf, plotly.graph_objects as go
from datetime import datetime
import importlib
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å®šä¹‰é¡¹ç›®æ ¹ç›®å½•
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.abspath(os.path.join(CURRENT_DIR, ".."))
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

try:
    from src.data.data_loader import DataLoader
    from src.data.news_harvester import NewsHarvester
    from src.models.vision_engine import VisionEngine
    from src.strategies.factor_mining import FactorMiner
    from src.strategies.fundamental import FundamentalMiner
    from src.agent.quant_agent import QuantAgent
    from src.utils.visualizer import create_comparison_plot
    from src.utils.pdf_generator import generate_report_pdf
    from src.utils.audio_manager import AudioManager
    from src.strategies.batch_analyzer import BatchAnalyzer
    from src.strategies.portfolio_optimizer import PortfolioOptimizer
    from src.strategies.kline_factor import KLineFactorCalculator
except ImportError as e:
    st.error(f"âŒ ç³»ç»Ÿæ¨¡å—åŠ è½½å¤±è´¥: {e}")
    st.stop()

def _code_version_key():
    paths = [
        os.path.join(PROJECT_ROOT, "src", "models", "vision_engine.py"),
        os.path.join(PROJECT_ROOT, "src", "strategies", "fundamental.py"),
    ]
    return "|".join([str(os.path.getmtime(p)) if os.path.exists(p) else "0" for p in paths])

def _find_existing_kline_image(symbol: str, date_str: str):
    symbol = str(symbol).zfill(6)
    date_n = str(date_str).replace("-", "")
    img_bases = [
        os.path.join(PROJECT_ROOT, "data", "images_v2"),
        os.path.join(PROJECT_ROOT, "data", "images"),
    ]
    for img_base in img_bases:
        candidates = [
            os.path.join(img_base, f"{symbol}_{date_n}.png"),
            os.path.join(img_base, symbol, f"{symbol}_{date_n}.png"),
            os.path.join(img_base, symbol, f"{date_n}.png"),
        ]
        for p in candidates:
            if os.path.exists(p):
                return p
        pattern = os.path.join(img_base, "**", f"*{symbol}*{date_n}*.png")
        matches = glob.glob(pattern, recursive=True)
        if matches:
            return matches[0]
    # å›é€€ï¼šå–è¯¥è‚¡ç¥¨æœ€æ–°çš„ä¸€å¼ å›¾
    all_imgs = []
    for img_base in img_bases:
        pattern2 = os.path.join(img_base, "**", f"{symbol}*.png")
        all_imgs.extend(glob.glob(pattern2, recursive=True))
    if not all_imgs:
        return None
    # å°è¯•æŒ‰æ—¥æœŸæ’åº
    def _extract_date(p):
        base = os.path.basename(p).replace(".png", "")
        parts = base.split("_")
        if len(parts) >= 2:
            return parts[1]
        return "00000000"
    all_imgs.sort(key=_extract_date, reverse=True)
    return all_imgs[0]

def _render_match_image(symbol: str, date_str: str, loader, out_path: str):
    try:
        df = loader.get_stock_data(symbol)
        if df is None or df.empty:
            return None
        df.index = pd.to_datetime(df.index)
        dt = pd.to_datetime(str(date_str), errors="coerce")
        if dt is pd.NaT:
            return None
        if dt not in df.index:
            candidates = df.index[df.index <= dt]
            if len(candidates) == 0:
                return None
            dt = candidates.max()
        loc = df.index.get_loc(dt)
        start = max(0, loc - 19)
        window = df.iloc[start:loc + 1].copy()
        if len(window) < 20:
            return None
        mc = mpf.make_marketcolors(up='red', down='green', inherit=True)
        s = mpf.make_mpf_style(marketcolors=mc, gridstyle='')
        mpf.plot(window, type='candle', style=s, savefig=dict(fname=out_path, dpi=50), figsize=(3, 3), axisoff=True)
        return out_path
    except Exception:
        return None

def _augment_matches(matches, query_img_path, query_prices, loader, vision_engine, tmp_dir):
    if not matches:
        return matches
    q_pix = vision_engine._load_pixel_vector(query_img_path)
    q_edge = vision_engine._load_edge_vector(query_img_path)
    for i, m in enumerate(matches):
        sym = str(m.get("symbol", "")).zfill(6)
        date_str = m.get("date")
        # 1) åƒç´ /è¾¹ç¼˜ç›¸ä¼¼åº¦å…œåº•
        if m.get("pixel_sim") is None or m.get("edge_sim") is None:
            path = vision_engine._resolve_image_path(m.get("path"), sym, date_str)
            if not path:
                tmp_path = os.path.join(tmp_dir, f"tmp_match_{sym}_{date_str}.png")
                path = _render_match_image(sym, date_str, loader, tmp_path)
            if path:
                v = vision_engine._load_pixel_vector(path)
                e = vision_engine._load_edge_vector(path)
                pix_cos = vision_engine._cosine_sim(q_pix, v)
                pix_corr = vision_engine._pearson_corr(q_pix, v)
                edge_cos = vision_engine._cosine_sim(q_edge, e) if q_edge is not None else None
                pix_cos = 0.0 if pix_cos is None else pix_cos
                pix_corr = 0.0 if pix_corr is None else pix_corr
                edge_cos = 0.0 if edge_cos is None else edge_cos
                pix_norm = (pix_cos + 1.0) / 2.0
                pix_corr_norm = (pix_corr + 1.0) / 2.0
                edge_norm = (edge_cos + 1.0) / 2.0
                visual_sim = 0.5 * pix_norm + 0.3 * pix_corr_norm + 0.2 * edge_norm
                m["pixel_sim"] = visual_sim
                m["edge_sim"] = edge_norm
            # fallback: ç”¨sim_scoreå¡«è¡¥ï¼Œé¿å…N/A
            if m.get("pixel_sim") is None:
                m["pixel_sim"] = m.get("sim_score", m.get("score", 0))
            if m.get("edge_sim") is None:
                m["edge_sim"] = m.get("pixel_sim")

        # 2) ç›¸å…³æ€§ä¸å›æŠ¥ç›¸å…³å…œåº•
        if (m.get("correlation") is None or m.get("ret_corr") is None) and query_prices is not None:
            try:
                dfp = loader.get_stock_data(sym)
                if dfp is not None and not dfp.empty:
                    dfp.index = pd.to_datetime(dfp.index)
                    dt = pd.to_datetime(str(date_str), errors="coerce")
                    if dt in dfp.index:
                        loc = dfp.index.get_loc(dt)
                        if loc >= 19:
                            match_prices = dfp.iloc[loc - 19: loc + 1]['Close'].values
                            qn = (query_prices - query_prices.mean()) / (query_prices.std() + 1e-8)
                            mn = (match_prices - match_prices.mean()) / (match_prices.std() + 1e-8)
                            corr = np.corrcoef(qn, mn)[0, 1]
                            if not np.isnan(corr):
                                m["correlation"] = float(corr)
                            q_ret = np.diff(query_prices) / (query_prices[:-1] + 1e-8)
                            m_ret = np.diff(match_prices) / (match_prices[:-1] + 1e-8)
                            q_ret = (q_ret - q_ret.mean()) / (q_ret.std() + 1e-8)
                            m_ret = (m_ret - m_ret.mean()) / (m_ret.std() + 1e-8)
                            corr2 = np.corrcoef(q_ret, m_ret)[0, 1]
                            if not np.isnan(corr2):
                                m["ret_corr"] = float(corr2)
            except Exception:
                pass
    return matches

st.set_page_config(page_title="VisionQuant Pro", layout="wide", page_icon="ğŸ¦„")
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    .stMetric { background-color: #ffffff; padding: 15px; border-radius: 10px; border: 1px solid #e6e9ef; }
    .agent-box { border-left: 5px solid #ff4b4b; padding: 20px; background-color: #fff1f1; border-radius: 5px; margin-bottom: 20px; }
    .stChatMessage { background-color: #ffffff; border-radius: 12px; padding: 12px; margin-bottom: 8px; box-shadow: 0 1px 3px rgba(0,0,0,0.08); }
    </style>
""", unsafe_allow_html=True)

@st.cache_resource
def load_all_engines(_code_version: str):
    ve_mod = importlib.import_module("src.models.vision_engine")
    fm_mod = importlib.import_module("src.strategies.fundamental")
    importlib.reload(ve_mod)
    importlib.reload(fm_mod)
    v = ve_mod.VisionEngine()
    v.reload_index()
    return {
        "loader": DataLoader(), "vision": v, "factor": FactorMiner(),
        "fund": fm_mod.FundamentalMiner(), "agent": QuantAgent(), 
        "news": NewsHarvester(), "audio": AudioManager()
    }

eng = load_all_engines(_code_version=_code_version_key())

if "chat_history" not in st.session_state: st.session_state.chat_history = []
if "last_context" not in st.session_state: st.session_state.last_context = ""
if "has_run" not in st.session_state: st.session_state.has_run = False
if "last_voice_text" not in st.session_state: st.session_state.last_voice_text = ""
if "batch_results" not in st.session_state: st.session_state.batch_results = {}
if "portfolio_weights" not in st.session_state: st.session_state.portfolio_weights = {}
if "portfolio_metrics" not in st.session_state: st.session_state.portfolio_metrics = {}
if "current_symbol" not in st.session_state: st.session_state.current_symbol = None

# URL è·³è½¬é¢„å¤„ç†ï¼šå…ˆå†™å…¥ session_stateï¼Œè®©ä¾§è¾¹æ æ§ä»¶åŒæ­¥
url_symbol = st.query_params.get("symbol")
if url_symbol:
    st.session_state["symbol_input"] = url_symbol
    st.session_state["mode_select"] = "ğŸ” å•åªè‚¡ç¥¨åˆ†æ"

from backtest_handlers import run_backtest, run_stratified_backtest_batch
from factor_analysis_handlers import show_factor_analysis as render_factor_analysis
from streamlit_mic_recorder import mic_recorder

with st.sidebar:
    st.title("ğŸ¦„ VisionQuant Pro")
    st.caption("AI å…¨æ ˆé‡åŒ–æŠ•ç ”ç³»ç»Ÿ v8.8")
    
    # === æ•°æ®æºé€‰æ‹© ===
    with st.expander("âš™ï¸ æ•°æ®æºè®¾ç½®", expanded=False):
        ds_map = {"AkShare (å…è´¹)": "akshare", "JQData (èšå®½)": "jqdata", "RQData (ç±³ç­)": "rqdata"}
        ds_label = st.selectbox("é€‰æ‹©æ•°æ®æº", list(ds_map.keys()), index=0)
        curr_ds = ds_map[ds_label]
        
        # å¦‚æœé€‰äº†ä»˜è´¹æºï¼Œæ£€æŸ¥/æç¤ºè¾“å…¥è´¦å·
        if curr_ds in ["jqdata", "rqdata"]:
            st.caption(f"éœ€æä¾› {curr_ds} è´¦å· (æˆ–è®¾ç½®ç¯å¢ƒå˜é‡)")
            ds_user = st.text_input("ç”¨æˆ·å", key=f"{curr_ds}_user")
            ds_pass = st.text_input("å¯†ç ", type="password", key=f"{curr_ds}_pass")
            if st.button("åˆ‡æ¢/è®¤è¯"):
                eng["loader"].switch_data_source(curr_ds, username=ds_user, password=ds_pass)
                st.success(f"å·²å°è¯•åˆ‡æ¢è‡³ {curr_ds}")
        else:
            if eng["loader"].get_current_data_source() != "akshare":
                eng["loader"].switch_data_source("akshare")

    st.divider()
    symbol_input = st.text_input("è¯·è¾“å…¥ A è‚¡ä»£ç ", value="601899", help="è¾“å…¥6ä½ä»£ç ", key="symbol_input")
    symbol = symbol_input.strip().zfill(6)
    mode = st.radio("åŠŸèƒ½æ¨¡å—:", ("ğŸ” å•åªè‚¡ç¥¨åˆ†æ", "ğŸ“Š æ‰¹é‡ç»„åˆåˆ†æ"), key="mode_select")

    if mode == "ğŸ” å•åªè‚¡ç¥¨åˆ†æ":
        st.divider()
        st.caption("å›æµ‹ / å› å­æœ‰æ•ˆæ€§åˆ†æå…¥å£å·²ç»Ÿä¸€æ”¾åœ¨â€œå•åªè‚¡ç¥¨åˆ†æâ€æŠ¥å‘Šåº•éƒ¨ Tab ä¸­ï¼ˆæ›´ç¬¦åˆä½¿ç”¨è·¯å¾„ï¼‰ã€‚")
    
    elif mode == "ğŸ“Š æ‰¹é‡ç»„åˆåˆ†æ":
        batch_input = st.text_area("è¾“å…¥è‚¡ç¥¨ä»£ç ï¼ˆæ¯è¡Œä¸€ä¸ªï¼Œæœ€å¤š30åªï¼‰", height=150, key="batch_input")

    st.divider()
    run_btn = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", use_container_width=True)

    if st.button("ğŸ”„ å¼ºåˆ¶é‡è½½", help="æ¸…é™¤ç¼“å­˜ï¼Œé‡æ–°åŠ è½½æ¨¡å—"):
        st.cache_resource.clear()
        st.rerun()

url_jump_mode = False
if url_symbol:
    if url_symbol != symbol:
        symbol = url_symbol
        url_jump_mode = True
        mode = "ğŸ” å•åªè‚¡ç¥¨åˆ†æ"
        st.session_state["symbol_input"] = symbol
        st.session_state["mode_select"] = "ğŸ” å•åªè‚¡ç¥¨åˆ†æ"
        if "res" in st.session_state:
            del st.session_state.res
        st.session_state.current_symbol = symbol
        st.session_state.has_run = True
        run_btn = True
    elif "res" not in st.session_state:
        url_jump_mode = True
        mode = "ğŸ” å•åªè‚¡ç¥¨åˆ†æ"
        st.session_state["mode_select"] = "ğŸ” å•åªè‚¡ç¥¨åˆ†æ"
        st.session_state.has_run = True
        run_btn = True
    else:
        st.query_params.clear()
        url_jump_mode = False

if not run_btn and not st.session_state.has_run:
    st.header(f"ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ VisionQuant Pro")
    st.info(f"å½“å‰é€‰ä¸­æ ‡çš„: **{symbol}**\nè¯·åœ¨å·¦ä¾§ä¾§è¾¹æ ç‚¹å‡»çº¢è‰²æŒ‰é’®å¯åŠ¨ã€‚")
    st.stop()

if mode == "ğŸ” å•åªè‚¡ç¥¨åˆ†æ":
    if st.session_state.current_symbol != symbol and st.session_state.current_symbol is not None:
        if "res" in st.session_state:
            del st.session_state.res
        st.session_state.has_run = False
        st.session_state.chat_history = []
        st.session_state.last_voice_text = ""
    
    if run_btn:
        st.session_state.has_run = True
        st.session_state.chat_history = []
        st.session_state.last_voice_text = ""
        st.session_state.current_symbol = symbol
        if "res" in st.session_state:
            del st.session_state.res

        progress = st.progress(0)
        status = st.empty()
        status.write("åŠ è½½è¡Œæƒ…æ•°æ®...")
        with st.spinner(f"æ­£åœ¨å…¨æ ˆæ‰«æ {symbol}..."):
            try:
                logger.info(f"å¼€å§‹åˆ†æè‚¡ç¥¨: {symbol}")
                df = eng["loader"].get_stock_data(symbol)
                if df.empty: 
                    st.error("æ•°æ®è·å–å¤±è´¥")
                    logger.error(f"æ•°æ®è·å–å¤±è´¥: {symbol}")
                    st.stop()
            except Exception as e:
                logger.exception(f"æ•°æ®è·å–å¼‚å¸¸: {symbol}")
                st.error(f"æ•°æ®è·å–å¤±è´¥: {str(e)}")
                st.stop()
            progress.progress(20)

            # æ•°æ®è´¨é‡æŠ¥å‘Š
            try:
                quality_report = eng["loader"].quality_checker.check_data_quality(df, symbol)
            except Exception:
                quality_report = {}
            progress.progress(30)

            fund_data = eng["fund"].get_stock_fundamentals(symbol)
            stock_name = fund_data.get('name', symbol)
            status.write("ç”ŸæˆæŸ¥è¯¢Kçº¿å›¾...")

            # ä¼˜å…ˆä½¿ç”¨å·²å­˜åœ¨çš„å†å²Kçº¿å›¾ï¼ˆä¿è¯ä¸ç´¢å¼•åŒåˆ†å¸ƒï¼‰
            date_str = df.index[-1].strftime("%Y%m%d")
            q_p = _find_existing_kline_image(symbol, date_str)
            if not q_p:
                q_p = os.path.join(PROJECT_ROOT, "data", "temp_q.png")
                mc = mpf.make_marketcolors(up='red', down='green', inherit=True)
                s = mpf.make_mpf_style(marketcolors=mc, gridstyle='')
                mpf.plot(df.tail(20), type='candle', style=s, savefig=dict(fname=q_p, dpi=50), figsize=(3, 3), axisoff=True)
            progress.progress(45)
            
            query_prices = df.tail(20)['Close'].values if len(df) >= 20 else None
            # å¤šå°ºåº¦æ£€ç´¢ï¼ˆæ—¥/å‘¨/æœˆï¼‰+ åŠ¨æ€æƒé‡èåˆ
            status.write("ç›¸ä¼¼å½¢æ€æ£€ç´¢ä¸­...")
            try:
                from src.data.multi_scale_generator import MultiScaleChartGenerator
                gen = MultiScaleChartGenerator(figsize=(3, 3), dpi=50)
                q_week = os.path.join(PROJECT_ROOT, "data", "temp_q_week.png")
                q_month = os.path.join(PROJECT_ROOT, "data", "temp_q_month.png")
                gen.generate_weekly_chart(df, weeks=20, output_path=q_week)
                gen.generate_monthly_chart(df, months=20, output_path=q_month)
                img_paths = {"daily": q_p, "weekly": q_week, "monthly": q_month}
                # åŠ¨æ€èåˆæƒé‡ï¼šåŸºäºå„å‘¨æœŸçš„æ”¶ç›Šåˆ†å¸ƒè´¨é‡è¯„åˆ†
                try:
                    kline_factor_calc = KLineFactorCalculator(data_loader=eng["loader"])
                    # ä»…ç”¨äºæƒé‡ä¼°è®¡ï¼Œä½¿ç”¨å¿«é€Ÿæ¨¡å¼å‡å°‘è€—æ—¶
                    scale_matches = {
                        "daily": eng["vision"].search_similar_patterns(
                            q_p, top_k=10, query_prices=query_prices, max_date=date_str,
                            fast_mode=True, search_k=400, rerank_with_pixels=False
                        ),
                        "weekly": eng["vision"].search_similar_patterns(
                            q_week, top_k=10, max_date=date_str,
                            fast_mode=True, search_k=400, rerank_with_pixels=False
                        ),
                        "monthly": eng["vision"].search_similar_patterns(
                            q_month, top_k=10, max_date=date_str,
                            fast_mode=True, search_k=400, rerank_with_pixels=False
                        ),
                    }
                    scale_stats = {
                        k: kline_factor_calc.calculate_return_distribution(v, horizon_days=5, query_date=date_str)
                        for k, v in scale_matches.items()
                    }
                    scale_weights = kline_factor_calc.estimate_scale_weights(scale_stats)
                except Exception:
                    scale_weights = None

                matches = eng["vision"].search_multi_scale_patterns(
                    img_paths, top_k=10, query_prices=query_prices, weights=scale_weights, max_date=date_str
                )
            except Exception:
                matches = eng["vision"].search_similar_patterns(q_p, top_k=10, query_prices=query_prices, max_date=date_str)
            progress.progress(65)

            # è¡¥é½ç›¸ä¼¼åº¦å­—æ®µï¼Œå‡å°‘ N/A
            matches = _augment_matches(matches, q_p, query_prices, eng["loader"], eng["vision"], os.path.join(PROJECT_ROOT, "data"))
            progress.progress(75)

            def get_future_trajectories(matches, loader):
                trajectories, details = [], []
                for m in matches:
                    try:
                        hdf = loader.get_stock_data(m['symbol'])
                        hdf.index = pd.to_datetime(hdf.index)
                        target_date = pd.to_datetime(m['date'])
                        if target_date in hdf.index:
                            loc = hdf.index.get_loc(target_date)
                            if loc + 5 < len(hdf):
                                subset = hdf.iloc[loc: loc + 6]['Close'].values
                                norm_path = (subset / subset[0] - 1) * 100
                                trajectories.append(norm_path)
                                details.append(f"{m['symbol']} ({m['date']})")
                    except:
                        continue
                return trajectories, details

            trajs, traj_labels = get_future_trajectories(matches, eng["loader"])

            if trajs:
                mean_path = np.mean(np.vstack(trajs), axis=0)
                avg_ret = mean_path[-1]
                traditional_win_rate = np.sum(np.vstack(trajs)[:, -1] > 0) / len(trajs) * 100
            else:
                mean_path, avg_ret, traditional_win_rate = np.zeros(6), 0.0, 50.0

            # Top10å¤šæœŸæ”¶ç›Š/åˆ†å¸ƒä¼°è®¡
            try:
                from src.utils.top10_analyzer import Top10Analyzer
                analyzer = Top10Analyzer(eng["loader"])
                mh_stats = analyzer.analyze_multi_horizon(matches, horizons=[5, 10, 20])
                dist_stats = analyzer.return_distribution(matches, future_days=20)
            except Exception:
                mh_stats, dist_stats = {}, {}

            try:
                kline_factor_calc = KLineFactorCalculator(data_loader=eng["loader"])
                query_date_str = datetime.now().strftime('%Y%m%d')
                hybrid_win_rate_result = kline_factor_calc.calculate_hybrid_win_rate(
                    matches, 
                    query_symbol=symbol,
                    query_date=query_date_str,
                    query_df=df
                )
                if isinstance(hybrid_win_rate_result, dict):
                    hybrid_win_rate = hybrid_win_rate_result.get('hybrid_win_rate', traditional_win_rate)
                else:
                    hybrid_win_rate = traditional_win_rate
                    hybrid_win_rate_result = None
                logger.info(f"æ··åˆèƒœç‡è®¡ç®—æˆåŠŸ: {symbol}, èƒœç‡={hybrid_win_rate:.1f}%")
            except Exception as e:
                logger.warning(f"æ··åˆèƒœç‡è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ä¼ ç»Ÿèƒœç‡: {symbol}, é”™è¯¯={str(e)}")
                hybrid_win_rate = traditional_win_rate
                hybrid_win_rate_result = None
            progress.progress(85)
            
            win_rate = hybrid_win_rate if hybrid_win_rate is not None else traditional_win_rate
            enhanced_factor = None
            enhanced_score = None
            if isinstance(hybrid_win_rate_result, dict):
                enhanced_factor = hybrid_win_rate_result.get("enhanced_factor")
                if isinstance(enhanced_factor, dict):
                    enhanced_score = enhanced_factor.get("final_score")
            # å¤šå› å­è¯„åˆ†ä½¿ç”¨å¢å¼ºå› å­åˆ†æ•°ï¼ˆè‹¥æœ‰ï¼‰ï¼Œå¦åˆ™å›é€€æ··åˆèƒœç‡
            win_rate_for_score = enhanced_score if enhanced_score is not None else win_rate

            df_f = eng["factor"]._add_technical_indicators(df)
            news_text = eng["news"].get_latest_news(symbol)
            ind_name, peers_df = eng["fund"].get_industry_peers(symbol)
            progress.progress(95)

            returns = df['Close'].pct_change().dropna()
            try:
                regime_weights = eng.get("regime_manager", None)
                if regime_weights:
                    regime_weights = regime_weights.calculate_dynamic_weights(returns=returns)
                    dynamic_weights = regime_weights.get('weights', {})
                else:
                    dynamic_weights = None
            except:
                dynamic_weights = None
            
            if dynamic_weights:
                total_score, initial_action, s_details = eng["factor"].get_scorecard(
                    win_rate_for_score, df_f.iloc[-1], fund_data, returns=returns
                )
            else:
                total_score, initial_action, s_details = eng["factor"].get_scorecard(
                    win_rate_for_score, df_f.iloc[-1], fund_data
                )

            report = eng["agent"].analyze(symbol, total_score, initial_action, {"win_rate": win_rate, "score": 0.9},
                                          df_f.iloc[-1].to_dict(), fund_data, news_text)

            c_p = os.path.join(PROJECT_ROOT, "data", "comparison.png")
            create_comparison_plot(q_p, matches, c_p)

            res_dict = {
                "name": stock_name, "c_p": c_p, "trajs": trajs, "mean": mean_path,
                "win": win_rate, "ret": avg_ret, "labels": traj_labels,
                "score": total_score, "act": initial_action, "det": s_details,
                "fund": fund_data, "df_f": df_f, "ind": ind_name, "peers": peers_df,
                "news": news_text, "rep": report,
                "mh_stats": mh_stats, "dist_stats": dist_stats,
                "matches": matches, "q_p": q_p,
                "quality_report": quality_report
            }
            if enhanced_factor:
                res_dict["enhanced_factor"] = enhanced_factor
                res_dict["enhanced_score"] = enhanced_score
            
            if hybrid_win_rate_result and hybrid_win_rate is not None:
                res_dict["hybrid_win_rate"] = hybrid_win_rate
                res_dict["traditional_win_rate"] = traditional_win_rate
                res_dict["tb_win_rate"] = hybrid_win_rate_result.get('tb_win_rate', 0)
                res_dict["win_rate_type"] = "æ··åˆèƒœç‡"
            else:
                res_dict["win_rate_type"] = "ä¼ ç»Ÿèƒœç‡"
            
            st.session_state.res = res_dict
            progress.progress(100)
            status.empty()
            st.session_state.last_context = f"""
            è‚¡ç¥¨åç§°: {stock_name} ({symbol})
            å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d')}
            --- é‡åŒ–æ•°æ® ---
            AIè¯„åˆ†: {total_score}/10
            è¶‹åŠ¿ä¿¡å·: {initial_action}
            å½¢æ€èƒœç‡: {win_rate:.1f}%
            --- è´¢åŠ¡æ•°æ® ---
            ROE: {fund_data.get('roe')}%
            PE(TTM): {fund_data.get('pe_ttm')}
            --- èˆ†æƒ…æ‘˜è¦ ---
            {news_text[:500]}
            --- åˆå§‹è§‚ç‚¹ ---
            {report.reasoning}
            """

            if url_jump_mode:
                st.session_state.clear_url_after_render = True

    if "res" in st.session_state:
        if st.session_state.get("clear_url_after_render", False):
            st.query_params.clear()
            st.session_state.clear_url_after_render = False
        
        d = st.session_state.res
        display_name = (d.get("name") or "").strip()
        if (not display_name) or (display_name == symbol):
            st.markdown(f"# ğŸ“Š æ·±åº¦æŠ•ç ”æŠ¥å‘Š: {symbol}")
        else:
            st.markdown(f"# ğŸ“Š æ·±åº¦æŠ•ç ”æŠ¥å‘Š: {display_name} ({symbol})")

        st.subheader("1. è§†è§‰æ¨¡å¼è¯†åˆ«")
        with st.expander("â„¹ï¸ æ•°æ®æ¥æºè¯´æ˜", expanded=False):
            st.markdown("""
            **Top10ç›¸ä¼¼Kçº¿åŒ¹é…**:
            - ä½¿ç”¨AttentionCAEæ¨¡å‹æå–Kçº¿å½¢æ€ç‰¹å¾
            - é€šè¿‡FAISSå‘é‡æ•°æ®åº“æœç´¢å†å²ç›¸ä¼¼æ¨¡å¼
            - åŒ¹é…ç»“æœåŒ…å«ï¼šè‚¡ç¥¨ä»£ç ã€æ—¥æœŸã€ç›¸ä¼¼åº¦åˆ†æ•°
            - è®¡ç®—è¿™äº›å†å²æ¨¡å¼çš„æœªæ¥è¡¨ç°ä½œä¸ºé¢„æµ‹ä¾æ®
            """)
        if d.get("quality_report"):
            with st.expander("ğŸ§ª æ•°æ®è´¨é‡æŠ¥å‘Š", expanded=False):
                qr = d["quality_report"]
                st.write(f"è´¨é‡è¯„åˆ†: {qr.get('score', 'N/A')}")
                st.write(f"æ ·æœ¬é‡: {qr.get('data_points', 'N/A')}")
                st.write(f"æ—¶é—´èŒƒå›´: {qr.get('date_range', {}).get('start')} ~ {qr.get('date_range', {}).get('end')}")
                if qr.get("missing_stats"):
                    st.write(f"ç¼ºå¤±ç‡: {qr['missing_stats'].get('missing_ratio', 0)*100:.2f}%")
                    by_col = qr["missing_stats"].get("by_column", {})
                    if by_col:
                        fig_miss = go.Figure()
                        fig_miss.add_trace(go.Bar(x=list(by_col.keys()), y=list(by_col.values())))
                        fig_miss.update_layout(height=250, title="ç¼ºå¤±å€¼åˆ†å¸ƒ")
                        st.plotly_chart(fig_miss, use_container_width=True)
                if qr.get("adjust_integrity"):
                    adj = qr["adjust_integrity"]
                    if adj.get("available"):
                        st.write(f"å¤æƒå®Œæ•´æ€§: {adj.get('column')} ç¼ºå¤±ç‡ {adj.get('missing_ratio', 0)*100:.2f}%")
                    else:
                        st.write("å¤æƒå®Œæ•´æ€§: æœªæä¾›å¤æƒåˆ—")
                if qr.get("warnings"):
                    st.write("è­¦å‘Š: " + "; ".join(qr.get("warnings", [])[:5]))
        st.image(d['c_p'], use_container_width=True)

        # ç›¸ä¼¼åº¦åˆ†è§£ï¼ˆè§†è§‰ç›¸ä¼¼åº¦/ç›¸å…³æ€§ï¼‰
        if d.get("matches"):
            rows = []
            for m in d["matches"]:
                vector_score = m.get("vector_score")
                corr = m.get("correlation")
                sim_score = m.get("sim_score")
                if sim_score is None:
                    if vector_score is not None:
                        sim_score = 1.0 / (1.0 + max(float(vector_score), 0.0))
                    else:
                        sim_score = m.get("score", 0)
                corr_norm = None if corr is None else (float(corr) + 1.0) / 2.0
                pix_sim = m.get("pixel_sim")
                edge_sim = m.get("edge_sim")
                ret_corr = m.get("ret_corr")
                rows.append({
                    "è‚¡ç¥¨": f"{m.get('symbol')}",
                    "æ—¥æœŸ": f"{m.get('date')}",
                    "ç›¸ä¼¼åº¦": round(float(sim_score), 4),
                    "åƒç´ ç›¸ä¼¼": round(float(pix_sim), 4) if pix_sim is not None else 0.0,
                    "è¾¹ç¼˜ç›¸ä¼¼": round(float(edge_sim), 4) if edge_sim is not None else 0.0,
                    "ç›¸å…³æ€§": round(float(corr_norm), 4) if corr_norm is not None else 0.0,
                    "å›æŠ¥ç›¸å…³": round(float((ret_corr+1)/2), 4) if ret_corr is not None else 0.0,
                    "æœ€ç»ˆåˆ†": round(float(m.get("score", 0)), 4)
                })
            with st.expander("ğŸ” ç›¸ä¼¼åº¦åˆ†è§£ï¼ˆå¯è§£é‡Šï¼‰", expanded=False):
                st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)

        # æ³¨æ„åŠ›çƒ­åŠ›å›¾ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
        try:
            if hasattr(eng["vision"].model, "get_attention_weights"):
                with st.expander("ğŸ”¥ æ³¨æ„åŠ›çƒ­åŠ›å›¾ï¼ˆè§£é‡Šæ€§ï¼‰", expanded=False):
                    mode = st.selectbox("æ˜¾ç¤ºæ–¹å¼", ["å¤šå¤´(å…¨éƒ¨)", "å•å¤´"], index=0, key="attn_mode")
                    heat_path = os.path.join(PROJECT_ROOT, "data", "temp_attention.png")
                    if mode == "å¤šå¤´(å…¨éƒ¨)":
                        eng["vision"].generate_attention_heatmap(d.get("q_p"), save_path=heat_path, mode="all")
                        st.image(heat_path, use_container_width=True)
                    else:
                        num_heads = getattr(eng["vision"].model, "num_attention_heads", 8)
                        head_idx = st.slider("é€‰æ‹©æ³¨æ„åŠ›å¤´", 0, max(0, num_heads - 1), 0, key="attn_head")
                        eng["vision"].generate_attention_heatmap(d.get("q_p"), save_path=heat_path, head_idx=head_idx, mode="single")
                        st.image(heat_path, use_container_width=True)
                    if os.path.exists(heat_path):
                        os.remove(heat_path)
        except Exception:
            pass
        if d['trajs']:
            fig = go.Figure()
            for i, p in enumerate(d['trajs']):
                fig.add_trace(go.Scatter(y=p, mode='lines', line=dict(color='rgba(200,200,200,0.5)', width=1),
                                         name=d['labels'][i]))
            fig.add_trace(go.Scatter(y=d['mean'], mode='lines+markers', line=dict(color='#d62728', width=3), name='å¹³å‡é¢„æœŸ'))
            fig.update_layout(title=f"æœªæ¥5æ—¥èµ°åŠ¿æ¨æ¼” (èƒœç‡: {d['win']:.0f}%)", xaxis_title="å¤©æ•°", yaxis_title="æ”¶ç›Š%", height=400)
            st.plotly_chart(fig, config={"displayModeBar": False}, use_container_width=True)
            c1, c2, c3, c4 = st.columns(4)
            c1.metric("å†å²èƒœç‡", f"{d['win']:.1f}%")
            c2.metric("é¢„æœŸæ”¶ç›Š", f"{d['ret']:.2f}%")
            if d.get("enhanced_score") is not None:
                c3.metric("å¢å¼ºå› å­åˆ†", f"{d['enhanced_score']:.2f}")
                c4.metric("ä¿¡å·å¼ºåº¦", d.get("enhanced_factor", {}).get("signal_level", "N/A"))
            else:
                c3.metric("å¢å¼ºå› å­åˆ†", "N/A")
                c4.metric("ä¿¡å·å¼ºåº¦", "N/A")
            
            # èƒœç‡è®¡ç®—å…¬å¼è¯´æ˜
            if d.get('win_rate_type') == 'æ··åˆèƒœç‡' and 'hybrid_win_rate' in d:
                with c3:
                    with st.expander("ğŸ“ èƒœç‡è®¡ç®—å…¬å¼", expanded=False):
                        st.markdown("""
                        **æ··åˆèƒœç‡ = Triple Barrierèƒœç‡ Ã— 70% + ä¼ ç»Ÿèƒœç‡ Ã— 30%**
                        
                        - **Triple Barrierèƒœç‡**: åŸºäºæ­¢ç›ˆ(+5%)ã€æ­¢æŸ(-3%)ã€æœ€å¤§æŒæœ‰20å¤©çš„æ ‡ç­¾ç»Ÿè®¡
                        - **ä¼ ç»Ÿèƒœç‡ï¼ˆç›¸ä¼¼åº¦åŠ æƒï¼‰**: æœªæ¥5æ—¥æ”¶ç›Šç‡>0 çš„æ¯”ä¾‹ï¼ŒæŒ‰ Top10 åŒ¹é…çš„ç›¸ä¼¼åº¦ `score` åŠ æƒ
                        - **æ•°æ®æ¥æº**: Top10ç›¸ä¼¼Kçº¿æ¨¡å¼çš„å†å²è¡¨ç°
                        """)
                        if 'tb_win_rate' in d:
                            st.caption(f"TBèƒœç‡: {d.get('tb_win_rate', 0):.1f}% | ä¼ ç»Ÿèƒœç‡: {d.get('traditional_win_rate', 0):.1f}%")

            # å¤šæœŸæ”¶ç›Šæ›²çº¿ï¼ˆ5/10/20ï¼‰
            mh = d.get("mh_stats", {})
            if mh.get("valid") and mh.get("horizon_stats"):
                hs = mh["horizon_stats"]
                mh_fig = go.Figure()
                for h, stats in hs.items():
                    mh_fig.add_trace(go.Scatter(
                        x=[h], y=[stats.get("avg_return", 0)],
                        mode="markers+text", text=[f"{h}æ—¥"],
                        name=f"{h}æ—¥"
                    ))
                mh_fig.update_layout(title="å¤šæœŸæ”¶ç›Šé¢„æœŸï¼ˆ5/10/20æ—¥ï¼‰", xaxis_title="æŒæœ‰æœŸ(å¤©)", yaxis_title="å‡å€¼æ”¶ç›Š(%)", height=280)
                st.plotly_chart(mh_fig, use_container_width=True)

            # æ”¶ç›Šåˆ†å¸ƒä¼°è®¡
            dist = d.get("dist_stats", {})
            if dist.get("valid"):
                with st.expander("ğŸ“Š æ”¶ç›Šåˆ†å¸ƒä¼°è®¡ï¼ˆæ›´ä¸¥æ ¼ï¼‰", expanded=False):
                    st.write(f"æ ·æœ¬æ•°: {dist.get('count')}")
                    st.write(f"å‡å€¼: {dist.get('mean'):.2f}% | ä¸­ä½æ•°: {dist.get('median'):.2f}%")
                    st.write(f"åˆ†ä½æ•°: Q05={dist.get('q05'):.2f}%, Q25={dist.get('q25'):.2f}%, Q75={dist.get('q75'):.2f}%")
                    st.write(f"CVaR(5%): {dist.get('cvar'):.2f}%")

            # å¤åˆå› å­è§£é‡Šï¼ˆåˆ†å¸ƒ + æƒ…å¢ƒ + é‡ä»·ï¼‰
            if d.get("enhanced_factor"):
                ef = d["enhanced_factor"]
                with st.expander("ğŸ§­ æƒ…å¢ƒæ„ŸçŸ¥ä¸é‡ä»·å¤åˆå› å­ï¼ˆæ–°å¢ï¼‰", expanded=False):
                    st.write(f"æœ€ä½³æŒæœ‰æœŸ: {ef.get('best_horizon', 'N/A')} å¤©")
                    st.write(f"ä¿¡å·å¼ºåº¦: {ef.get('signal_level', 'N/A')} | å¢å¼ºå› å­åˆ†: {ef.get('final_score', 'N/A')}")
                    context = ef.get("context", {})
                    st.caption(f"Regime: {context.get('regime')} | æ³¢åŠ¨ç‡: {context.get('volatility')} | æµåŠ¨æ€§è¯„åˆ†: {context.get('liquidity_score')}")
                    money = ef.get("money_features", {})
                    if money:
                        st.write("é‡ä»·/èµ„é‡‘ç‰¹å¾:")
                        st.json(money)
                    dist_map = ef.get("dist_map", {})
                    if dist_map:
                        rows = []
                        for h, stats in dist_map.items():
                            if not stats or not stats.get("valid"):
                                continue
                            rows.append({
                                "æŒæœ‰æœŸ": h,
                                "å‡å€¼": round(stats.get("mean", 0), 2),
                                "èƒœç‡": round(stats.get("win_rate", 0), 2),
                                "CVaR": round(stats.get("cvar", 0), 2),
                                "ååº¦": stats.get("skew"),
                                "å³°åº¦": stats.get("kurt"),
                                "èµ”ç‡": stats.get("odds")
                            })
                        if rows:
                            st.dataframe(pd.DataFrame(rows), use_container_width=True, hide_index=True)

        st.divider()
        c_left, c_right = st.columns([1.5, 1])
        with c_left:
            st.subheader("2. é‡åŒ–å¤šå› å­çœ‹æ¿")
            with st.expander("â„¹ï¸ å› å­è¯´æ˜", expanded=False):
                st.markdown("""
                **å¤šå› å­è¯„åˆ†ç³»ç»Ÿ (V+F+Q)**:
                - **V (è§†è§‰å› å­)**: Kçº¿å­¦ä¹ å› å­èƒœç‡ï¼Œæƒé‡60%
                - **F (åŸºæœ¬é¢å› å­)**: ROEã€PEã€PBç­‰ï¼Œæƒé‡20%
                - **Q (æŠ€æœ¯å› å­)**: MAã€RSIã€MACDç­‰ï¼Œæƒé‡20%
                - **åŠ¨æ€æƒé‡**: æ ¹æ®å¸‚åœºregimeè‡ªåŠ¨è°ƒæ•´
                """)
            m1, m2, m3, m4 = st.columns(4)
            m1.metric("AI æ€»è¯„åˆ†", f"{d['score']}/10", delta=d['act'])
            fund_ok = (d.get("fund", {}) or {}).get("_ok", {})
            m2.metric("ROE", f"{d['fund'].get('roe')}%" if fund_ok.get("finance") else "N/A")
            m3.metric("PE", f"{d['fund'].get('pe_ttm')}" if fund_ok.get("spot") else "N/A")
            m4.metric("è¶‹åŠ¿", "çœ‹æ¶¨" if d['df_f'].iloc[-1]['MA_Signal'] > 0 else "çœ‹è·Œ")

            with st.expander("ğŸ“Š æœé‚¦åˆ†æ & å› å­æ˜ç»†"):
                col_a, col_b = st.columns(2)
                with col_a:
                    st.write("**æœé‚¦æ‹†è§£**")
                    if fund_ok.get("finance"):
                        st.write(f"å‡€åˆ©ç‡: {d['fund'].get('net_profit_margin')}%")
                        st.write(f"å‘¨è½¬ç‡: {d['fund'].get('asset_turnover')}")
                        st.write(f"æƒç›Šä¹˜æ•°: {d['fund'].get('leverage')}x")
                with col_b:
                    st.write("**æŠ€æœ¯å› å­**")
                    st.json(d['det'])

            # è§£é‡Šæ€§è¯„åˆ†ï¼ˆV/F/Qè´¡çŒ®ï¼‰
            det = d.get("det", {})
            try:
                v = float(det.get("è§†è§‰åˆ†(V)", 0))
                f = float(det.get("è´¢åŠ¡åˆ†(F)", 0))
                q = float(det.get("é‡åŒ–åˆ†(Q)", 0))
                total = v + f + q if (v + f + q) > 0 else 1.0
                contrib = pd.DataFrame([
                    {"å› å­": "è§†è§‰(V)", "è´¡çŒ®": f"{v/total*100:.1f}%"},
                    {"å› å­": "åŸºæœ¬é¢(F)", "è´¡çŒ®": f"{f/total*100:.1f}%"},
                    {"å› å­": "æŠ€æœ¯(Q)", "è´¡çŒ®": f"{q/total*100:.1f}%"},
                ])
                with st.expander("ğŸ§  å¯è§£é‡Šæ€§è¯„åˆ†è´¡çŒ®", expanded=False):
                    st.dataframe(contrib, use_container_width=True, hide_index=True)
            except Exception:
                pass

            # æ”¶ç›Šå½’å› ï¼ˆè§†è§‰/æŠ€æœ¯/åŸºæœ¬é¢ï¼‰
            try:
                attribution = pd.DataFrame([
                    {"æ¥æº": "è§†è§‰å› å­", "å½±å“": round(v, 2)},
                    {"æ¥æº": "æŠ€æœ¯å› å­", "å½±å“": round(q, 2)},
                    {"æ¥æº": "åŸºæœ¬é¢å› å­", "å½±å“": round(f, 2)},
                ])
                with st.expander("ğŸ“Œ æ”¶ç›Šå½’å› ï¼ˆå› å­è´¡çŒ®ï¼‰", expanded=False):
                    st.dataframe(attribution, use_container_width=True, hide_index=True)
            except Exception:
                pass

        with c_right:
            st.subheader(f"3. è¡Œä¸šå¯¹æ ‡ ({d['ind']})")
            st.dataframe(d['peers'], hide_index=True)

        st.divider()
        st.subheader("4. æ–°é—»èˆ†æƒ…")
        with st.expander("â„¹ï¸ æ•°æ®æ¥æº", expanded=False):
            st.markdown("""
            **æ–°é—»æ•°æ®æ¥æº**: 
            - é€šè¿‡akshareæ¥å£è·å–æœ€æ–°æ–°é—»
            - åŒ…å«å…¬å¸å…¬å‘Šã€è¡Œä¸šåŠ¨æ€ã€å¸‚åœºèµ„è®¯
            """)
        st.info(d['news'])

        # ---- å•åªè‚¡ç¥¨é¡µï¼šå…ˆå› å­/å›æµ‹ï¼Œæœ€å AI ----
        st.divider()
        tab_bt, tab_fa = st.tabs(["ğŸ§ª å›æµ‹", "ğŸ“ˆ å› å­æœ‰æ•ˆæ€§åˆ†æ"])

        with tab_bt:
            st.subheader("ğŸ§ª ç­–ç•¥æ¨¡æ‹Ÿå›æµ‹")
            with st.expander("â„¹ï¸ å›æµ‹è¯´æ˜", expanded=False):
                st.markdown("""
                **å›æµ‹ç­–ç•¥é€»è¾‘**:
                - **ä»“ä½è®¡ç®—**: åŸºäºMA60ã€MA20ã€MACDå’ŒAIèƒœç‡é˜ˆå€¼
                - **Transaction Cost**: ä½£é‡‘(0.1%) + æ»‘ç‚¹(0.1%) + å¸‚åœºå†²å‡» + æœºä¼šæˆæœ¬
                - **Turnoverçº¦æŸ**: å•æ—¥æœ€å¤§æ¢æ‰‹ç‡20%
                - **æ¶¨è·Œåœ/åœç‰Œçº¦æŸ**: æ¶¨åœä¸è¿½ã€è·Œåœä¸ç ã€åœç‰Œä¸äº¤æ˜“ï¼ˆAè‚¡æ‰§è¡Œçº¦æŸï¼‰
                - **æ­¢æŸæœºåˆ¶**: è¾¾åˆ°æ­¢æŸé˜ˆå€¼(-8%)æ—¶å¼ºåˆ¶å¹³ä»“
                - **Walk-Forward**: æ»šåŠ¨çª—å£éªŒè¯ï¼Œé˜²æ­¢æœªæ¥å‡½æ•°æ³„æ¼
                """)

            cbt1, cbt2, cbt3, cbt4 = st.columns(4)
            with cbt1:
                bt_start_val = st.date_input("å¼€å§‹æ—¥æœŸ", value=st.session_state.get("bt_start", datetime(2022, 1, 1)), key="bt_start")
            with cbt2:
                bt_end_val = st.date_input("ç»“æŸæ—¥æœŸ", value=st.session_state.get("bt_end", datetime.now()), key="bt_end")
            with cbt3:
                bt_cap_val = st.number_input("åˆå§‹èµ„é‡‘", value=st.session_state.get("bt_cap", 100000), key="bt_cap")
            with cbt4:
                bt_ma_val = st.slider("MAå‘¨æœŸ", 20, 120, st.session_state.get("bt_ma", 60), key="bt_ma")

            cbt5, cbt6, cbt7 = st.columns(3)
            with cbt5:
                bt_stop_val = st.slider("æ­¢æŸ%", 1, 20, st.session_state.get("bt_stop", 8), key="bt_stop")
            with cbt6:
                bt_vision_val = st.slider("AIèƒœç‡é˜ˆå€¼", 40, 80, st.session_state.get("bt_vision", 57), key="bt_vision")
            with cbt7:
                bt_validation_val = st.selectbox("éªŒè¯æ¨¡å¼", ["ç®€å•å›æµ‹", "Walk-ForwardéªŒè¯ï¼ˆä¸¥æ ¼ï¼‰"], index=0 if st.session_state.get("bt_validation", "ç®€å•å›æµ‹") == "ç®€å•å›æµ‹" else 1, key="bt_validation")

            if bt_validation_val == "Walk-ForwardéªŒè¯ï¼ˆä¸¥æ ¼ï¼‰":
                wf1, wf2 = st.columns(2)
                with wf1:
                    wf_train_months_val = st.slider("è®­ç»ƒæœŸ(æœˆ)", 6, 36, st.session_state.get("wf_train_months", 24), key="wf_train_months")
                with wf2:
                    wf_test_months_val = st.slider("æµ‹è¯•æœŸ(æœˆ)", 1, 12, st.session_state.get("wf_test_months", 6), key="wf_test_months")
            else:
                wf_train_months_val, wf_test_months_val = 24, 6

            enable_stress = st.checkbox(
                "å¯ç”¨Stress Testing",
                value=st.session_state.get("enable_stress", False),
                key="enable_stress",
                help="åœ¨æç«¯å¸‚åœºæ¡ä»¶ä¸‹æµ‹è¯•ç­–ç•¥é²æ£’æ€§ï¼ˆ2008é‡‘èå±æœºã€2020ç–«æƒ…å´©ç›˜ã€2015è‚¡ç¾ï¼‰",
            )
            strict_no_future = st.checkbox(
                "ä¸¥æ ¼æ— æœªæ¥å‡½æ•°ï¼ˆæ›´æ…¢ï¼‰",
                value=st.session_state.get("strict_no_future", True),
                key="strict_no_future",
                help="ä»…ä½¿ç”¨å½“å‰æ—¥æœŸåŠä¹‹å‰çš„ç›¸ä¼¼å½¢æ€ï¼Œé¿å…æœªæ¥æ•°æ®æ³„æ¼"
            )
            if strict_no_future:
                cbt8, cbt9 = st.columns(2)
                with cbt8:
                    ai_stride_val = st.slider(
                        "AIè¯„ä¼°æ­¥é•¿(å¤©)",
                        1, 20,
                        st.session_state.get("ai_stride", 5),
                        key="ai_stride",
                        help="æ­¥é•¿è¶Šå¤§è¶Šå¿«ï¼Œä½†ç²¾åº¦ä¼šä¸‹é™ï¼›è®¾ä¸º1è¡¨ç¤ºé€æ—¥è¯„ä¼°"
                    )
                with cbt9:
                    ai_fast_mode_val = st.checkbox(
                        "å¿«é€ŸAIè¯„ä¼°ï¼ˆå‘é‡è¿‘ä¼¼ï¼‰",
                        value=st.session_state.get("ai_fast_mode", True),
                        key="ai_fast_mode",
                        help="è·³è¿‡DTW/ç›¸å…³æ€§è®¡ç®—ï¼Œæ˜¾è‘—åŠ é€Ÿä½†ç²¾åº¦ç•¥é™"
                    )
            else:
                ai_stride_val, ai_fast_mode_val = 1, False

            if st.button("å¼€å§‹å›æµ‹", key="backtest_btn"):
                run_backtest(
                    symbol, bt_start_val, bt_end_val, bt_cap_val, bt_ma_val,
                    bt_stop_val, bt_vision_val, bt_validation_val,
                    wf_train_months_val, wf_test_months_val, eng, PROJECT_ROOT,
                    enable_stress_test=enable_stress, strict_no_future=strict_no_future,
                    ai_stride=ai_stride_val, ai_fast_mode=ai_fast_mode_val
                )

        with tab_fa:
            st.subheader("ğŸ“ˆ å› å­æœ‰æ•ˆæ€§åˆ†æ")
            render_factor_analysis(symbol, d["df_f"], eng, PROJECT_ROOT)

        st.divider()
        st.subheader("5. AI åŸºé‡‘ç»ç†ç»ˆå®¡")
        color = "green" if d['rep'].action == "BUY" else "red" if d['rep'].action == "SELL" else "orange"
        st.markdown(f"""
        <div class="agent-box">
            <h2 style="color:{color}; margin:0">{d['rep'].action}</h2>
            <p>ä¿¡å¿ƒ: {d['rep'].confidence}% | é£é™©: {d['rep'].risk_level}</p>
            <hr><p>{d['rep'].reasoning}</p>
        </div>
        """, unsafe_allow_html=True)

        pdf_p = os.path.join(PROJECT_ROOT, "data", f"Report_{symbol}.pdf")
        if st.button("ğŸ“„ å¯¼å‡º PDF"):
            generate_report_pdf(f"{d['name']}({symbol})", d['rep'], d['c_p'], pdf_p)
            with open(pdf_p, "rb") as f:
                st.download_button("ä¸‹è½½ PDF", f, file_name=f"VQ_{symbol}.pdf")

        st.divider()
        st.subheader("ğŸ’¬ æ™ºèƒ½å¯¹è¯")
        for msg in st.session_state.chat_history:
            with st.chat_message(msg["role"]): 
                st.markdown(msg["content"])

        c_mic, c_input = st.columns([1, 8])
        user_voice_text = None
        with c_mic:
            st.write(" ")
            audio = mic_recorder(start_prompt="ğŸ™ï¸", stop_prompt="â¹ï¸", key='recorder', format='wav')
        if audio:
            transcribed = eng["audio"].transcribe(audio['bytes'])
            if transcribed and transcribed != st.session_state.last_voice_text:
                user_voice_text = transcribed
                st.session_state.last_voice_text = transcribed
        with c_input:
            text_input = st.chat_input("è¾“å…¥é—®é¢˜...")
        final_input = user_voice_text if user_voice_text else text_input

        if final_input:
            st.session_state.chat_history.append({"role": "user", "content": final_input})
            st.rerun()

        if st.session_state.chat_history and st.session_state.chat_history[-1]["role"] == "user":
            user_q = st.session_state.chat_history[-1]["content"]
            with st.chat_message("assistant"):
                with st.spinner("æ€è€ƒä¸­..."):
                    resp = eng["agent"].chat(user_q, st.session_state.last_context)
                    st.markdown(resp)
                    st.session_state.chat_history.append({"role": "assistant", "content": resp})

elif mode == "ğŸ“Š æ‰¹é‡ç»„åˆåˆ†æ":
    if run_btn:
        symbols = [s.strip().zfill(6) for s in batch_input.split('\n') if s.strip()][:30]
        if len(symbols) == 0:
            st.error("âŒ è¯·è¾“å…¥è‡³å°‘ä¸€åªè‚¡ç¥¨ä»£ç ")
            st.stop()
        
        st.session_state.has_run = True
        if "batch_results" in st.session_state:
            del st.session_state.batch_results
        if "multi_tier_result" in st.session_state:
            del st.session_state.multi_tier_result
        if "portfolio_metrics" in st.session_state:
            del st.session_state.portfolio_metrics
        
        batch_analyzer = BatchAnalyzer(eng)
        portfolio_optimizer = PortfolioOptimizer()
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        def update_progress(current, total, symbol):
            progress = current / total
            progress_bar.progress(progress)
            status_text.text(f"æ­£åœ¨åˆ†æ {symbol} ({current}/{total})...")
        
        batch_results = batch_analyzer.analyze_batch(symbols, progress_callback=update_progress)
        st.session_state.batch_results = batch_results
        progress_bar.progress(1.0)
        status_text.text("âœ… åˆ†æå®Œæˆ")
        progress_bar.empty()
        status_text.empty()

        if not batch_results:
            st.error("æ‰¹é‡åˆ†æå¤±è´¥æˆ–æ— æœ‰æ•ˆæ•°æ®")
            st.stop()

        # ç»Ÿä¸€ç»„åˆä¼˜åŒ–ï¼ˆå³ä½¿æ²¡æœ‰ BUY ä¹Ÿèƒ½è¾“å‡ºâ€œå¢å¼ºç»„åˆâ€ï¼‰
        multi_tier_result = portfolio_optimizer.optimize_multi_tier_portfolio(
            batch_results, eng["loader"], min_weight=0.05, max_weight=0.25, max_positions=10
        )
        st.session_state.multi_tier_result = multi_tier_result

        buy_stocks = {k: v for k, v in batch_results.items() if v.get('action') == 'BUY' and v.get('score', 0) >= 7}
        wait_stocks = {k: v for k, v in batch_results.items() if v.get('action') == 'WAIT'}
        sell_stocks = {k: v for k, v in batch_results.items() if v.get('action') == 'SELL'}

        def _goto_symbol(sym: str):
            if "res" in st.session_state:
                del st.session_state.res
            st.session_state.current_symbol = None
            st.session_state.has_run = False
            st.session_state["symbol_input"] = sym
            st.session_state["mode_select"] = "ğŸ” å•åªè‚¡ç¥¨åˆ†æ"
            st.query_params.update({"symbol": sym, "mode": "detail"})
            st.rerun()

        tier_info = multi_tier_result.get("tier_info", {})
        if tier_info:
            st.info(
                f"ç»„åˆç­–ç•¥: {tier_info.get('strategy', '-')}"
                f" | ä¼˜åŒ–å™¨: {tier_info.get('optimizer', 'Black-Litterman')}"
                f" | è¯´æ˜: {tier_info.get('description', '-')}"
            )

        st.subheader("âœ… ç»„åˆç»“æœï¼ˆæ ¸å¿ƒ + å¤‡é€‰ï¼‰")
        core_weights = multi_tier_result.get('core', {})
        enhanced_weights = multi_tier_result.get('enhanced', {})
        combined_weights = {}
        combined_weights.update(core_weights)
        combined_weights.update(enhanced_weights)

        def _render_weights_table(title, weights):
            st.markdown(f"### {title}")
            if not weights:
                st.info("æš‚æ— å¯ç”¨ç»„åˆ")
                return
            rows = []
            for sym, w in sorted(weights.items(), key=lambda x: x[1], reverse=True):
                data = batch_results.get(sym, {})
                rows.append({
                    "è‚¡ç¥¨ä»£ç ": sym,
                    "è‚¡ç¥¨åç§°": data.get("name", sym),
                    "æƒé‡": f"{w*100:.1f}%",
                    "è¯„åˆ†": f"{data.get('score', 0):.1f}/10",
                    "èƒœç‡": f"{data.get('win_rate', 0):.1f}%",
                    "é¢„æœŸæ”¶ç›Š": f"{data.get('expected_return', 0):.2f}%"
                })
            st.dataframe(pd.DataFrame(rows), hide_index=True, use_container_width=True)

            for sym, w in sorted(weights.items(), key=lambda x: x[1], reverse=True):
                data = batch_results.get(sym, {})
                c1, c2, c3, c4 = st.columns([3, 1, 1, 4])
                with c1:
                    if st.button(f"ğŸ“Š {data.get('name', sym)} ({sym})", key=f"link_{title}_{sym}", use_container_width=True):
                        _goto_symbol(sym)
                with c2:
                    st.write(f"**{data.get('score', 0):.1f}/10**")
                with c3:
                    st.write(f"{w*100:.1f}%")
                with c4:
                    st.write(f"{data.get('action', 'WAIT')} - {data.get('reasoning', '')[:60]}")

        _render_weights_table("æ ¸å¿ƒæ¨èç»„åˆ", core_weights)
        _render_weights_table("å¤‡é€‰å¢å¼ºç»„åˆ", enhanced_weights)

        st.subheader("ğŸ“Œ ä»“ä½è®¾è®¡ä¸é£æ§è®¾ç½®")
        c1, c2, c3 = st.columns(3)
        c1.metric("æœ€å°ä»“ä½", "5%")
        c2.metric("æœ€å¤§ä»“ä½", "25%")
        c3.metric("æœ€å¤§æŒä»“æ•°", "10")
        st.caption("æ­¢ç›ˆ/æ­¢æŸå‚è€ƒï¼šæ ‡ç­¾æ­¢ç›ˆ +5%ã€æ ‡ç­¾æ­¢æŸ -3%ï¼›å›æµ‹æ­¢æŸé»˜è®¤ -8%ï¼ˆå¯åœ¨å•è‚¡å›æµ‹ä¸­è°ƒæ•´ï¼‰")

        if combined_weights:
            st.subheader("ğŸ“Š ç»„åˆæƒé‡å›¾è¡¨")
            # æ‹¥æŒ¤äº¤æ˜“æŒ‡æ ‡
            hhi = sum([w**2 for w in combined_weights.values()])
            top3 = sum(sorted(combined_weights.values(), reverse=True)[:3])
            st.caption(f"æ‹¥æŒ¤åº¦(HHI): {hhi:.4f} | å‰ä¸‰é›†ä¸­åº¦: {top3*100:.1f}%")
            
            # ç»„åˆæŒ‡æ ‡ä¸é£é™©é¢„ç®—
            try:
                metrics = portfolio_optimizer.calculate_portfolio_metrics(combined_weights, batch_results, eng["loader"])
                if metrics:
                    st.subheader("ğŸ§¾ ç»„åˆé£é™©æŒ‡æ ‡")
                    m1, m2, m3, m4 = st.columns(4)
                    m1.metric("æœŸæœ›æ”¶ç›Š", f"{metrics.get('expected_return', 0):.2f}%")
                    m2.metric("é£é™©(æ³¢åŠ¨)", f"{metrics.get('risk', 0):.2f}%")
                    m3.metric("Sharpe", f"{metrics.get('sharpe_ratio', 0):.2f}")
                    m4.metric("CVaR(5%)", f"{metrics.get('cvar', 0):.2f}%")
                    if metrics.get("risk_budget"):
                        with st.expander("é£é™©é¢„ç®—åˆ†è§£", expanded=False):
                            rb = pd.DataFrame(
                                [{"symbol": k, "risk_contrib": v} for k, v in metrics["risk_budget"].items()]
                            )
                            st.dataframe(rb, use_container_width=True, hide_index=True)
            except Exception:
                pass

            # å†å¹³è¡¡å»ºè®®ï¼ˆåŸºäºä¸Šæ¬¡æƒé‡ + æ¢æ‰‹ä¸Šé™ï¼‰
            prev_weights = st.session_state.get("portfolio_weights", {})
            try:
                rebalance_weights, rebalance_info = portfolio_optimizer.propose_rebalance(
                    prev_weights, combined_weights, max_turnover=0.20
                )
                st.session_state.portfolio_weights = combined_weights
                with st.expander("ğŸ” å†å¹³è¡¡å»ºè®®ï¼ˆæ¢æ‰‹â‰¤20%ï¼‰", expanded=False):
                    st.write(f"é¢„è®¡æ¢æ‰‹: {rebalance_info.get('turnover', 0)*100:.1f}%")
                    r_df = pd.DataFrame([
                        {"symbol": s, "current": round(prev_weights.get(s, 0)*100, 1), "target": round(rebalance_weights.get(s, 0)*100, 1)}
                        for s in set(prev_weights) | set(rebalance_weights)
                    ])
                    st.dataframe(r_df, use_container_width=True, hide_index=True)
            except Exception:
                pass
            labels = [f"{batch_results[s].get('name', s)}({s})" for s in combined_weights.keys()]
            values = [combined_weights[s] for s in combined_weights.keys()]
            pie = go.Figure(data=[go.Pie(labels=labels, values=values, hole=0.35)])
            pie.update_layout(height=320, title="ç»„åˆæƒé‡åˆ†å¸ƒ")
            st.plotly_chart(pie, use_container_width=True)

            bar = go.Figure()
            bar.add_trace(go.Bar(x=labels, y=[batch_results[s].get('score', 0) for s in combined_weights.keys()],
                                 name="è¯„åˆ†", marker_color="#ff4b4b"))
            bar.update_layout(height=300, title="è¯„åˆ†å¯¹æ¯”")
            st.plotly_chart(bar, use_container_width=True)

            scatter = go.Figure()
            for s in combined_weights.keys():
                scatter.add_trace(go.Scatter(
                    x=[batch_results[s].get('win_rate', 0)],
                    y=[batch_results[s].get('expected_return', 0)],
                    mode='markers+text',
                    text=[s],
                    marker=dict(size=max(8, combined_weights[s]*200), color="#1f77b4"),
                    name=s
                ))
            scatter.update_layout(height=320, title="èƒœç‡ vs é¢„æœŸæ”¶ç›Š", xaxis_title="èƒœç‡(%)", yaxis_title="é¢„æœŸæ”¶ç›Š(%)")
            st.plotly_chart(scatter, use_container_width=True)

            st.subheader("ğŸ•¯ï¸ ç»„åˆTop3 Kçº¿å±•ç¤º")
            top_syms = [s for s, _ in sorted(combined_weights.items(), key=lambda x: x[1], reverse=True)[:3]]
            if top_syms:
                cols = st.columns(len(top_syms))
                for i, sym in enumerate(top_syms):
                    try:
                        dfk = eng["loader"].get_stock_data(sym)
                        if dfk is None or dfk.empty:
                            continue
                        tmp_img = os.path.join(PROJECT_ROOT, "data", f"temp_batch_k_{sym}.png")
                        mc = mpf.make_marketcolors(up='red', down='green', inherit=True)
                        sstyle = mpf.make_mpf_style(marketcolors=mc, gridstyle='')
                        mpf.plot(dfk.tail(60), type='candle', style=sstyle,
                                 savefig=dict(fname=tmp_img, dpi=80), figsize=(4, 3), axisoff=True)
                        with cols[i]:
                            st.image(tmp_img, caption=f"{sym}", use_container_width=True)
                        if os.path.exists(tmp_img):
                            os.remove(tmp_img)
                    except Exception:
                        continue

            # åˆ†å±‚å›æµ‹ï¼ˆè¡Œä¸š/å¸‚å€¼/é£æ ¼ + æ˜¾è‘—æ€§ï¼‰
            with st.expander("ğŸ§ª åˆ†å±‚å›æµ‹ï¼ˆè¡Œä¸š/å¸‚å€¼/é£æ ¼ï¼‰", expanded=False):
                if st.button("è¿è¡Œåˆ†å±‚å›æµ‹", key="strat_bt_btn"):
                    strat_df = run_stratified_backtest_batch(list(batch_results.keys()), eng)
                    if strat_df is not None and not strat_df.empty:
                        st.dataframe(strat_df, use_container_width=True, hide_index=True)
                    else:
                        st.info("åˆ†å±‚æ ·æœ¬ä¸è¶³æˆ–æ•°æ®ä¸å¯ç”¨")

            # æƒé‡åŠ¨æ€å˜åŒ–ï¼ˆç®€åŒ–ï¼šåŸºäº20æ—¥åŠ¨é‡çš„æœˆåº¦å†å¹³è¡¡ï¼‰
            try:
                st.subheader("ğŸ“ˆ ç»„åˆæƒé‡åŠ¨æ€å˜åŒ–")
                top_syms = list(combined_weights.keys())[:6]
                weight_df = pd.DataFrame()
                for sym in top_syms:
                    dfw = eng["loader"].get_stock_data(sym)
                    if dfw is None or dfw.empty:
                        continue
                    dfw.index = pd.to_datetime(dfw.index)
                    dfw = dfw.tail(180)
                    mom = dfw["Close"].pct_change(20)
                    dfw = dfw.assign(mom=mom)
                    dfw = dfw.resample("M").last().dropna()
                    weight_df[sym] = dfw["mom"]
                if not weight_df.empty:
                    # å½’ä¸€åŒ–ä¸ºæƒé‡
                    weight_df = weight_df.apply(lambda x: x - x.min() + 1e-6)
                    weight_df = weight_df.div(weight_df.sum(axis=1), axis=0)
                    fig_w = go.Figure()
                    for sym in weight_df.columns:
                        fig_w.add_trace(go.Scatter(x=weight_df.index, y=weight_df[sym], mode="lines", name=sym))
                    fig_w.update_layout(height=320, title="æœˆåº¦æƒé‡æ¼”åŒ–ï¼ˆåŠ¨é‡é©±åŠ¨ï¼‰")
                    st.plotly_chart(fig_w, use_container_width=True)
            except Exception:
                pass

            # æ»šåŠ¨æ”¶ç›Šçƒ­å›¾
            try:
                st.subheader("ğŸ§Š æ»šåŠ¨æ”¶ç›Šçƒ­å›¾ï¼ˆ20æ—¥ï¼‰")
                heat_syms = list(combined_weights.keys())[:8]
                heat_data = []
                heat_index = None
                for sym in heat_syms:
                    dfh = eng["loader"].get_stock_data(sym)
                    if dfh is None or dfh.empty:
                        continue
                    dfh.index = pd.to_datetime(dfh.index)
                    dfh = dfh.tail(200)
                    roll = dfh["Close"].pct_change(20) * 100
                    if heat_index is None:
                        heat_index = roll.index
                    heat_data.append(roll.reindex(heat_index).fillna(0).values)
                if heat_data:
                    heat = go.Figure(data=go.Heatmap(
                        z=np.array(heat_data),
                        x=[d.strftime("%Y-%m-%d") for d in heat_index],
                        y=heat_syms,
                        colorscale="RdYlGn"
                    ))
                    heat.update_layout(height=320)
                    st.plotly_chart(heat, use_container_width=True)
            except Exception:
                pass
        
        if wait_stocks or sell_stocks:
            st.divider()
            st.subheader("âš ï¸ è§‚æœ›/å–å‡ºåˆ—è¡¨")
            all_other = {**wait_stocks, **sell_stocks}
            if all_other:
                for symbol, data in sorted(all_other.items(), key=lambda x: x[1].get('score', 0)):
                    col1, col2, col3 = st.columns([3, 1, 4])
                    with col1:
                        if st.button(f"ğŸ“Š {data.get('name', symbol)} ({symbol})", 
                                   key=f"link_other_{symbol}", use_container_width=True):
                            _goto_symbol(symbol)
                    with col2:
                        st.write(f"**{data.get('score', 0):.1f}/10**")
                    with col3:
                        st.write(f"{data.get('action', 'WAIT')} - {data.get('reasoning', '')[:50]}")
                    st.divider()
    
    else:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§è¾“å…¥è‚¡ç¥¨ä»£ç å¹¶ç‚¹å‡»å¯åŠ¨")
