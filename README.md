# VisionQuant-Pro v2.0

<div align="center">

**Vision-Based Quantitative Trading System with Deep Learning**

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-orange.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

*Dual-Stream Architecture | GAF Encoding | Triple Barrier | Walk-Forward Validation*

</div>

---

## ğŸ“Š Current Status

| Component | Status | Notes |
|-----------|--------|-------|
| **v1.5 Web Interface** | âœ… Working | Uses 400K K-line images, fully functional |
| **v1.5 AttentionCAE Model** | âœ… Trained | 5 epochs on 400K images |
| **v1.5 FAISS Index** | âœ… Built | 400K vectors indexed |
| **v2.0 Framework Code** | âœ… Complete | ~4,600 lines, all imports verified |
| **v2.0 GAF Images** | â³ Pending | Run `scripts/prepare_data.py` to generate |
| **v2.0 Dual-Stream Model** | â³ Pending | Run `scripts/train_dual_stream.py` to train |

> **Note**: v2.0 is currently a **framework implementation**. The architecture and training scripts are complete, but model training has not been executed yet. The existing v1.5 system remains fully functional.

---

## ğŸ‡¨ğŸ‡³ ç‰ˆæœ¬è¿­ä»£è¯´æ˜ (Version Evolution in Chinese)

<details>
<summary>ç‚¹å‡»å±•å¼€æŸ¥çœ‹ä¸­æ–‡ç‰ˆæœ¬å¯¹æ¯”</summary>

### v1.0 â†’ v2.0 æ ¸å¿ƒæ”¹è¿›

| ç»´åº¦ | v1.0 é—®é¢˜ | v2.0 è§£å†³æ–¹æ¡ˆ |
|------|----------|--------------|
| **ä¿¡æ¯ä¸¢å¤±** | Kçº¿æˆªå›¾ä¸¢å¤±ç²¾ç¡®æ•°å€¼ | GAFæ•°å­¦ç¼–ç  + åŒæµä¿ç•™åŸå§‹OHLCV |
| **æ ‡ç­¾ç®€å•** | ç®€å•æ¶¨è·ŒäºŒåˆ†ç±» | Triple Barrierä¸‰åˆ†ç±»ï¼ˆæ­¢ç›ˆ/æ­¢æŸ/éœ‡è¡ï¼‰ |
| **æœªæ¥å‡½æ•°** | éšæœºåˆ’åˆ†æ•°æ®é›† | Walk-Forwardæ»šåŠ¨éªŒè¯ |
| **ç¼ºä¹ç†è®º** | "çœ‹å›¾è¯´è¯"å¼è¯„åˆ† | æœ‰æ•°å­¦å®šä¹‰çš„GAF/Triple Barrier |
| **ä¸å¯è§£é‡Š** | é»‘ç›’æ¨¡å‹ | Grad-CAMçƒ­åŠ›å›¾ + æ³¨æ„åŠ›æƒé‡å¯è§†åŒ– |
| **å›æµ‹ç®€é™‹** | è‡ªå†™ç®€å•å›æµ‹ | Backtraderä¸“ä¸šæ¡†æ¶ |

### æ¶æ„æ¼”è¿›å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        VERSION EVOLUTION                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  v1.0 (2026-01-05)          v1.5 (2026-01-10)                    â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                    â”‚
â”‚  Kçº¿æˆªå›¾                     Kçº¿æˆªå›¾                              â”‚
â”‚     â”‚                           â”‚                                 â”‚
â”‚     â†“                           â†“                                 â”‚
â”‚  QuantCAE                   AttentionCAE                          â”‚
â”‚  (4å±‚CNN)                   (CAE + 8å¤´æ³¨æ„åŠ›)                     â”‚
â”‚     â”‚                           â”‚                                 â”‚
â”‚     â†“                           â†“                                 â”‚
â”‚  FAISSæ£€ç´¢                  FAISSæ£€ç´¢                             â”‚
â”‚     â”‚                           â”‚                                 â”‚
â”‚     â†“                           â†“                                 â”‚
â”‚  èƒœç‡é¢„æµ‹                    V+F+Qå¤šå› å­è¯„åˆ†                       â”‚
â”‚                                                                   â”‚
â”‚                          v2.0 (2026-01-13)                        â”‚
â”‚                          â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€                        â”‚
â”‚                          OHLCVåŸå§‹æ•°æ®                            â”‚
â”‚                               â”‚                                   â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚                    â†“                     â†“                        â”‚
â”‚               GAFå›¾åƒ               æ ‡å‡†åŒ–åºåˆ—                     â”‚
â”‚                    â”‚                     â”‚                        â”‚
â”‚                    â†“                     â†“                        â”‚
â”‚               ResNet18              TCN+Attention                  â”‚
â”‚                    â”‚                     â”‚                        â”‚
â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚                               â†“                                   â”‚
â”‚                      Cross-Modal Attention                        â”‚
â”‚                               â”‚                                   â”‚
â”‚                               â†“                                   â”‚
â”‚                      Triple Barrieré¢„æµ‹                           â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ–°å¢ä»£ç é‡ç»Ÿè®¡

| æ–‡ä»¶ | åŠŸèƒ½ | ä»£ç è¡Œæ•° |
|------|------|---------|
| `gaf_encoder.py` | GAFå›¾åƒç¼–ç  | 491 |
| `triple_barrier.py` | Triple Barrieræ ‡ç­¾ | 549 |
| `walk_forward.py` | Walk-ForwardéªŒè¯ | 638 |
| `temporal_encoder.py` | TCN+Attentionæ—¶åºç¼–ç  | 579 |
| `dual_stream_network.py` | åŒæµèåˆç½‘ç»œ | 711 |
| `backtrader_strategy.py` | Backtraderç­–ç•¥é›†æˆ | 555 |
| `train_dual_stream.py` | è®­ç»ƒè„šæœ¬ | 523 |
| `grad_cam.py` | Grad-CAMå¯è§†åŒ– | 517 |
| **æ€»è®¡** | | **~4,600** |

</details>

---

## What's New in v2.0

- **Dual-Stream Architecture**: Vision Stream (GAF images) + Temporal Stream (TCN+Attention)
- **GAF Encoding**: Gramian Angular Field - mathematically rigorous time-to-image conversion
- **Triple Barrier Method**: Industry-standard labeling (profit-taking, stop-loss, time horizon)
- **Walk-Forward Validation**: Prevent look-ahead bias with rolling window training
- **Backtrader Integration**: Professional backtesting framework
- **Grad-CAM Explainability**: Visualize what the model "sees" in charts

---

## Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      VisionQuant-Pro v2.0                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚    Vision Stream    â”‚         â”‚   Temporal Stream   â”‚           â”‚
â”‚  â”‚                     â”‚         â”‚                     â”‚           â”‚
â”‚  â”‚  OHLCV â†’ GAF Image  â”‚         â”‚  OHLCV â†’ Sequence   â”‚           â”‚
â”‚  â”‚       â†“            â”‚         â”‚       â†“            â”‚           â”‚
â”‚  â”‚  ResNet18/ViT      â”‚         â”‚  TCN + Attention   â”‚           â”‚
â”‚  â”‚       â†“            â”‚         â”‚       â†“            â”‚           â”‚
â”‚  â”‚  [B, 512] features â”‚         â”‚  [B, 256] features â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚             â”‚                               â”‚                       â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                             â†“                                       â”‚
â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
â”‚             â”‚   Cross-Modal Attention       â”‚                       â”‚
â”‚             â”‚      [B, 768] fused           â”‚                       â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                       â”‚
â”‚                             â”‚                                       â”‚
â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚        â†“                    â†“                    â†“                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚  FAISS    â”‚       â”‚ Triple    â”‚       â”‚   Risk    â”‚             â”‚
â”‚  â”‚  Search   â”‚       â”‚ Barrier   â”‚       â”‚   Eval    â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Innovations

### 1. GAF Encoding (Gramian Angular Field)

Unlike simple K-line chart screenshots, GAF provides **mathematically rigorous** time-to-image conversion:

```python
# Mathematical formulation
x_scaled = (x - min) / (max - min) * 2 - 1  # Normalize to [-1, 1]
Ï† = arccos(x_scaled)                         # Polar angle
G[i,j] = cos(Ï†_i + Ï†_j)                      # GASF matrix
```

**3-Channel GAF Image**:
- **R**: GASF (Gramian Angular Summation Field) - captures overall trends
- **G**: GADF (Gramian Angular Difference Field) - captures local changes
- **B**: MTF (Markov Transition Field) - captures state transitions

### 2. Dual-Stream Fusion

**Vision Stream**: Processes GAF images with ResNet18/ViT
- Captures spatial patterns (Double Bottom, Head-and-Shoulders, etc.)
- Pretrained on ImageNet for transfer learning

**Temporal Stream**: Processes raw OHLCV with TCN + Self-Attention
- TCN: Dilated causal convolutions for local patterns
- Self-Attention: Long-range dependencies across time

**Cross-Modal Attention**: Learns complementary information
- Gate mechanism balances vision vs. temporal importance
- Enables interpretation: "Which modality contributed more?"

### 3. Triple Barrier Labeling

Standard in quantitative finance (LÃ³pez de Prado, 2018):

```python
def get_label(price_series, pt=0.05, sl=0.03, max_holding=20):
    """
    pt: profit-taking threshold (5%)
    sl: stop-loss threshold (3%)
    max_holding: maximum holding period (20 days)
    
    Returns:
    - 1: Hit profit-taking first â†’ Bullish
    - -1: Hit stop-loss first â†’ Bearish
    - 0: Hit time horizon first â†’ Neutral
    """
```

### 4. Walk-Forward Validation

Prevents look-ahead bias by simulating real trading:

```
|------ Train (3 years) ------|-- Val (6mo) --|-- Test (6mo) --|
                              |
                              â†“ Roll forward
|------ Train (3 years) ------|-- Val (6mo) --|-- Test (6mo) --|
```

---

## Project Structure

```
VisionQuant-Pro/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ dual_stream_network.py  # Core: Dual-Stream Architecture
â”‚   â”‚   â”œâ”€â”€ temporal_encoder.py      # TCN + Self-Attention
â”‚   â”‚   â”œâ”€â”€ attention_cae.py         # Legacy: AttentionCAE
â”‚   â”‚   â””â”€â”€ vision_engine.py         # FAISS search engine
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ gaf_encoder.py           # GAF image generation
â”‚   â”‚   â”œâ”€â”€ triple_barrier.py        # Label generation
â”‚   â”‚   â””â”€â”€ data_loader.py           # Stock data loader
â”‚   â”œâ”€â”€ strategies/
â”‚   â”‚   â”œâ”€â”€ backtrader_strategy.py   # Backtrader integration
â”‚   â”‚   â”œâ”€â”€ portfolio_optimizer.py   # Markowitz optimization
â”‚   â”‚   â””â”€â”€ factor_mining.py         # Multi-factor scoring
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ walk_forward.py          # Walk-Forward validation
â”‚       â””â”€â”€ grad_cam.py              # Explainability
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train_dual_stream.py         # Training script
â”‚   â””â”€â”€ prepare_data.py              # Data preparation
â”œâ”€â”€ web/
â”‚   â””â”€â”€ app.py                       # Streamlit interface
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ AttentionCAEåˆ‡æ¢æŒ‡å—.md
â”‚   â”œâ”€â”€ å¸¸è§é—®é¢˜FAQ.md
â”‚   â””â”€â”€ åœ¨çº¿éƒ¨ç½²æ•™ç¨‹.md
â””â”€â”€ requirements.txt
```

---

## Quick Start

### Installation

```bash
git clone https://github.com/panyisheng095-ux/VisionQuant-Pro.git
cd VisionQuant-Pro

python -m venv venv
source venv/bin/activate  # Linux/Mac

pip install -r requirements.txt
```

### Data Preparation

```bash
# Generate GAF images and labels
python scripts/prepare_data.py --symbols 600519 000858 601899 --window 60
```

### Training

```bash
# Train dual-stream network with Walk-Forward validation
python scripts/train_dual_stream.py \
    --data_dir data \
    --gaf_dir data/gaf_images \
    --batch_size 32 \
    --num_epochs 50
```

### Web Interface

```bash
python run.py  # or: PYTHONPATH=. streamlit run web/app.py
```

---

## Comparison with Other Approaches

| Aspect | Traditional Quant | Pure CNN | RD-Agent | VisionQuant v2.0 |
|--------|------------------|----------|----------|------------------|
| Input | Numerical | K-line image | Numerical+Text | **GAF+OHLCV** |
| Time Modeling | Hand-crafted | Ignored | Agent reasoning | **TCN+Attention** |
| Image Encoding | None | Screenshot | None | **GAF (math-based)** |
| Explainability | High | Low | Medium | **High (Grad-CAM)** |
| Labeling | Returns | Up/Down | Returns | **Triple Barrier** |
| Validation | Random split | Random split | Rolling | **Walk-Forward** |

---

## Theoretical Foundation

### Behavioral Finance Justification

> "The market is driven by human behavior, and humans are visual creatures."

- **Anchoring Bias**: Traders anchor to visually prominent patterns (support/resistance)
- **Herding Behavior**: Visual breakouts trigger collective action
- **Representativeness Heuristic**: Similar charts â†’ similar future outcomes

Our model formalizes these intuitions:
- GAF preserves the visual structure traders see
- Cross-modal fusion captures both "what it looks like" and "how it moves"
- Historical pattern matching exploits behavioral repetition

### Information Theoretic View

```
I(FutureReturn; GAF+OHLCV) > I(FutureReturn; OHLCV)
```

The visual representation captures geometric and topological features that are difficult to extract from raw numerical sequences.

---

## Performance Notes

### Expected Results
- **Classification Accuracy**: 45-55% (3-class, beating random 33%)
- **Return Prediction MAE**: 2-4%
- **Alpha vs Buy-and-Hold**: Varies by market condition

### Disclaimer
- **This is a research project, NOT investment advice**
- Past performance does not guarantee future results
- Quantitative trading involves significant risk

---

## Roadmap

### v2.1 (Next)
- [ ] Vision Transformer (ViT) backbone option
- [ ] Contrastive learning (SimCLR) pretraining
- [ ] Multi-timeframe fusion (daily + weekly + monthly)

### v2.2 (Future)
- [ ] Reinforcement learning integration
- [ ] Live trading API integration
- [ ] Multi-market support (US, HK)

---

## Citation

```bibtex
@software{visionquant-pro,
  title = {VisionQuant-Pro: Dual-Stream Vision-Based Quantitative Trading},
  author = {Pan, Yisheng},
  year = {2025},
  url = {https://github.com/panyisheng095-ux/VisionQuant-Pro}
}
```

---

## References

- Wang, Z., & Oates, T. (2015). Imaging time-series to improve classification and imputation. IJCAI.
- LÃ³pez de Prado, M. (2018). Advances in Financial Machine Learning. Wiley.
- Selvaraju, R. R., et al. (2017). Grad-CAM: Visual Explanations from Deep Networks.
- Bai, S., et al. (2018). An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling.

---

## Version History

### Detailed Changelog

---

### v2.0.0 (2026-01-13) - Major Architecture Overhaul

**This is a complete rewrite focused on academic rigor and industrial applicability.**

#### âš¡ Core Architecture Changes

| Component | v1.0 | v2.0 | Improvement |
|-----------|------|------|-------------|
| **Image Encoding** | K-line screenshot (matplotlib) | **GAF (Gramian Angular Field)** | æ•°å­¦ä¸¥è°¨çš„æ—¶åºâ†’å›¾åƒè½¬æ¢ï¼Œä¿ç•™æ—¶é—´ä¾èµ–æ€§ |
| **Network** | Single-stream CAE | **Dual-Stream (Vision+Temporal)** | åŒæ—¶åˆ©ç”¨è§†è§‰ç©ºé—´ä¿¡æ¯å’Œæ—¶åºåŠ¨æ€ä¿¡æ¯ |
| **Vision Encoder** | Custom 4-layer CNN | **ResNet18 (pretrained)** | ImageNeté¢„è®­ç»ƒï¼Œæ›´å¼ºçš„ç‰¹å¾æå–èƒ½åŠ› |
| **Temporal Encoder** | None | **TCN + Self-Attention** | æ•æ‰é•¿è·ç¦»æ—¶åºä¾èµ– |
| **Fusion Method** | None | **Cross-Modal Attention** | å¯å­¦ä¹ çš„æ¨¡æ€èåˆæƒé‡ |

#### ğŸ“Š Data & Labels

| Component | v1.0 | v2.0 | Improvement |
|-----------|------|------|-------------|
| **Input Data** | Kçº¿æˆªå›¾ (PNG) | **GAF 3é€šé“å›¾åƒ + åŸå§‹OHLCV** | æ— ä¿¡æ¯ä¸¢å¤±ï¼Œç²¾ç¡®æ•°å€¼ä¿ç•™ |
| **Label Definition** | ç®€å•æ¶¨è·Œ (+5å¤©æ”¶ç›Šç‡>0) | **Triple Barrier Method** | ä¸šç•Œæ ‡å‡†ï¼Œè€ƒè™‘æ­¢ç›ˆ/æ­¢æŸ/æ—¶é—´é™åˆ¶ |
| **Label Classes** | 2ç±» (æ¶¨/è·Œ) | **3ç±» (çœ‹æ¶¨/éœ‡è¡/çœ‹è·Œ)** | æ›´ç¬¦åˆå®é™…äº¤æ˜“å†³ç­– |

#### ğŸ”¬ Training & Validation

| Component | v1.0 | v2.0 | Improvement |
|-----------|------|------|-------------|
| **Data Split** | éšæœº 90/10 | **Walk-Forward æ»šåŠ¨éªŒè¯** | é˜²æ­¢æœªæ¥å‡½æ•°æ³„éœ² |
| **Validation** | å•æ¬¡éªŒè¯é›† | **æ»šåŠ¨çª—å£å¤šæ¬¡éªŒè¯** | æ›´å¯é çš„æ³›åŒ–èƒ½åŠ›è¯„ä¼° |
| **Training Loss** | MSEé‡å»ºæŸå¤± | **åˆ†ç±»CE + å›å½’MSE + å¯¹æ¯”æŸå¤±** | å¤šä»»åŠ¡è”åˆä¼˜åŒ– |

#### ğŸ“ˆ Backtesting

| Component | v1.0 | v2.0 | Improvement |
|-----------|------|------|-------------|
| **Framework** | è‡ªå†™ç®€å•å›æµ‹ | **Backtrader ä¸“ä¸šæ¡†æ¶** | å·¥ä¸šçº§å›æµ‹èƒ½åŠ› |
| **Metrics** | ç®€å•æ”¶ç›Šç‡ | **Sharpe/Calmar/MaxDD/èƒœç‡/ç›ˆäºæ¯”** | å®Œæ•´ç»©æ•ˆè¯„ä¼° |
| **Look-ahead Bias** | æœªä¸¥æ ¼é˜²èŒƒ | **ä¸¥æ ¼æ—¶é—´éš”ç¦»** | å¯ä¿¡çš„å›æµ‹ç»“æœ |

#### ğŸ¯ Explainability

| Component | v1.0 | v2.0 | Improvement |
|-----------|------|------|-------------|
| **Model Interpretation** | Attentionæƒé‡çƒ­åŠ›å›¾ | **Grad-CAM + Attention + æ¨¡æ€æƒé‡** | å¤šå±‚æ¬¡å¯è§£é‡Šæ€§ |
| **Visualization** | å•ä¸€æ³¨æ„åŠ›å›¾ | **GAFçƒ­åŠ›å›¾ + æ—¶åºæ³¨æ„åŠ› + èåˆæƒé‡** | å®Œæ•´çš„å†³ç­–è§£é‡Šé“¾ |

#### ğŸ“ New Files Added (v2.0)

```
src/data/
â”œâ”€â”€ gaf_encoder.py          # [NEW] GAFå›¾åƒç¼–ç å™¨ (491 lines)
â””â”€â”€ triple_barrier.py       # [NEW] Triple Barrieræ ‡ç­¾ (549 lines)

src/models/
â”œâ”€â”€ temporal_encoder.py     # [NEW] TCN+Attentionæ—¶åºç¼–ç å™¨ (579 lines)
â””â”€â”€ dual_stream_network.py  # [NEW] åŒæµèåˆç½‘ç»œ (711 lines)

src/strategies/
â””â”€â”€ backtrader_strategy.py  # [NEW] Backtraderç­–ç•¥ (555 lines)

src/utils/
â”œâ”€â”€ walk_forward.py         # [NEW] Walk-ForwardéªŒè¯ (638 lines)
â””â”€â”€ grad_cam.py             # [NEW] Grad-CAMå¯è§†åŒ– (517 lines)

scripts/
â””â”€â”€ train_dual_stream.py    # [NEW] åŒæµç½‘ç»œè®­ç»ƒè„šæœ¬ (523 lines)
```

**Total new code: ~4,600 lines**

---

### v1.5.0 (2026-01-10) - Attention Enhancement

#### Changes from v1.0
- **AttentionCAE**: åœ¨CAEæœ«ç«¯æ·»åŠ 8å¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶
- **Multi-factor Scoring**: V(è§†è§‰)+F(è´¢åŠ¡)+Q(é‡åŒ–)ä¸‰å› å­è¯„åˆ†
- **Batch Analysis**: æ”¯æŒ30åªè‚¡ç¥¨æ‰¹é‡åˆ†æ
- **Portfolio Optimization**: Markowitzå‡å€¼-æ–¹å·®ä¼˜åŒ–
- **AI Agent**: é›†æˆGoogle Geminiå¤§æ¨¡å‹è¾…åŠ©åˆ†æ

#### Files Added (v1.5)
```
src/models/attention_cae.py        # æ³¨æ„åŠ›å¢å¼ºCAE
src/strategies/batch_analyzer.py   # æ‰¹é‡åˆ†æå¼•æ“
src/strategies/portfolio_optimizer.py  # ç»„åˆä¼˜åŒ–å™¨
src/utils/attention_visualizer.py  # æ³¨æ„åŠ›å¯è§†åŒ–
```

---

### v1.0.0 (2026-01-05) - Initial Release

#### Core Features
- **QuantCAE**: 4å±‚å·ç§¯è‡ªç¼–ç å™¨ï¼Œå­¦ä¹ Kçº¿å›¾å½¢æ€
- **FAISS Search**: å‘é‡ç›¸ä¼¼åº¦æœç´¢ï¼Œæ¯«ç§’çº§æ£€ç´¢
- **Streamlit Web**: äº¤äº’å¼Webç•Œé¢
- **åŸºç¡€å›æµ‹**: ç®€å•çš„ä¹°å…¥æŒæœ‰å¯¹æ¯”

#### Architecture (v1.0)
```
Kçº¿æˆªå›¾ (matplotlib)
    â†“
QuantCAE (4-layer CNN)
    â†“
FAISS Index (L2 distance)
    â†“
Top-K Similar Patterns
    â†“
Win Rate Prediction
```

#### Limitations Identified
1. âŒ Kçº¿æˆªå›¾ä¸¢å¤±ç²¾ç¡®æ•°å€¼ä¿¡æ¯
2. âŒ çº¯CNNæ— æ³•æ•æ‰é•¿è·ç¦»ä¾èµ–
3. âŒ ç®€å•æ¶¨è·Œæ ‡ç­¾ä¸ç¬¦åˆå®é™…äº¤æ˜“
4. âŒ éšæœºæ•°æ®åˆ’åˆ†å¯¼è‡´æœªæ¥å‡½æ•°é£é™©
5. âŒ ç¼ºä¹ä¸¥è°¨çš„å›æµ‹æ¡†æ¶

---

### Version Comparison Summary

```
v1.0 Architecture:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Kçº¿æˆªå›¾ â†’ CAE Encoder â†’ FAISS â†’ Win Rate â†’ Simple Score

v1.5 Architecture:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Kçº¿æˆªå›¾ â†’ AttentionCAE â†’ FAISS â†’ Win Rate â†’ Multi-Factor Score
                â†‘                              â†‘
          + Attention                    + V+F+Q Factors

v2.0 Architecture:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
         â”Œâ†’ GAF Image â†’ ResNet18 â”€â”€â”€â”€â”€â”€â”
OHLCV â”€â”€â”€â”¤                              â”œâ†’ Cross-Modal Attention â†’ Triple Barrier
         â””â†’ Sequence  â†’ TCN+Attention â”€â”˜
```

---

## License

MIT License - see [LICENSE](LICENSE)

---

<div align="center">

**If you find this project useful, please give it a â­ Star!**

Made with â¤ï¸ by [panyisheng095-ux](https://github.com/panyisheng095-ux)

</div>
