import os
import sys
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import faiss
import pickle
import glob
import pandas as pd
import numpy as np
from datetime import datetime
from scipy.spatial.distance import cdist

# === 1. åŸºç¡€é…ç½® ===
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
os.environ['OMP_NUM_THREADS'] = '1'

# === 2. è·¯å¾„é…ç½® ===
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(CURRENT_DIR))
# ä¼˜å…ˆä½¿ç”¨ AttentionCAEï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å›é€€åˆ° QuantCAE
ATTENTION_MODEL_PATH = os.path.join(PROJECT_ROOT, "data", "models", "attention_cae_best.pth")
CAE_MODEL_PATH = os.path.join(PROJECT_ROOT, "data", "models", "cae_best.pth")
# ç´¢å¼•æ–‡ä»¶è·¯å¾„ï¼ˆä¼˜å…ˆç”¨æ–°ç´¢å¼•ï¼‰
ATTENTION_INDEX_FILE = os.path.join(PROJECT_ROOT, "data", "indices", "cae_faiss_attention.bin")
ATTENTION_META_CSV = os.path.join(PROJECT_ROOT, "data", "indices", "meta_data_attention.csv")
INDEX_FILE = os.path.join(PROJECT_ROOT, "data", "indices", "cae_faiss.bin")
META_CSV = os.path.join(PROJECT_ROOT, "data", "indices", "meta_data.csv")
META_PKL = os.path.join(PROJECT_ROOT, "data", "indices", "meta.pkl")

if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)
from src.models.attention_cae import AttentionCAE


def _dtw_distance(s1, s2, window=5):
    """
    å¿«é€ŸDTW (Dynamic Time Warping) è·ç¦»è®¡ç®—
    ä½¿ç”¨Sakoe-Chibaå¸¦çº¦æŸåŠ é€Ÿï¼Œå¤æ‚åº¦ä»O(nÂ²)é™åˆ°O(n*window)
    
    Args:
        s1, s2: ä¸¤ä¸ªä»·æ ¼åºåˆ—
        window: å¸¦çº¦æŸçª—å£å¤§å°ï¼ˆé»˜è®¤5ï¼Œå³å…è®¸Â±5çš„æ—¶é—´åç§»ï¼‰
    """
    try:
        n, m = len(s1), len(s2)
        if n == 0 or m == 0:
            return float('inf')
        
        # å½’ä¸€åŒ–åˆ°0-1ï¼ˆä¿ç•™å½¢æ€ï¼Œæ¶ˆé™¤ç»å¯¹ä»·æ ¼å·®å¼‚ï¼‰
        s1 = np.array(s1, dtype=float)
        s2 = np.array(s2, dtype=float)
        s1 = (s1 - np.min(s1)) / (np.max(s1) - np.min(s1) + 1e-8)
        s2 = (s2 - np.min(s2)) / (np.max(s2) - np.min(s2) + 1e-8)
        
        # Sakoe-Chibaå¸¦çº¦æŸDTW
        dtw_matrix = np.full((n + 1, m + 1), float('inf'))
        dtw_matrix[0, 0] = 0
        
        for i in range(1, n + 1):
            # åªè®¡ç®—çª—å£å†…çš„ç‚¹
            j_start = max(1, i - window)
            j_end = min(m + 1, i + window + 1)
            for j in range(j_start, j_end):
                cost = abs(s1[i - 1] - s2[j - 1])
                dtw_matrix[i, j] = cost + min(
                    dtw_matrix[i - 1, j],      # æ’å…¥
                    dtw_matrix[i, j - 1],      # åˆ é™¤
                    dtw_matrix[i - 1, j - 1]   # åŒ¹é…
                )
        
        # å½’ä¸€åŒ–åˆ°0-1èŒƒå›´ï¼ˆè·ç¦»è¶Šå°è¶Šç›¸ä¼¼ï¼‰
        return dtw_matrix[n, m] / max(n, m)
    except Exception:
        return float('inf')


def _extract_kline_features(prices):
    """
    æå–Kçº¿å½¢æ€çš„å…³é”®ç‰¹å¾å‘é‡ï¼ˆç”¨äºå½¢æ€åŒ¹é…ï¼‰
    è¿”å›8ç»´ç‰¹å¾ï¼š
    1. æ•´ä½“è¶‹åŠ¿æ–¹å‘ (æ¶¨/è·Œ)
    2. æ¶¨è·Œå¹…
    3. æ³¢åŠ¨ç‡
    4. æœ€é«˜ç‚¹ä½ç½®ï¼ˆç›¸å¯¹ï¼‰
    5. æœ€ä½ç‚¹ä½ç½®ï¼ˆç›¸å¯¹ï¼‰
    6. å¤´éƒ¨å½¢æ€ï¼ˆå‰1/3æ¶¨è·Œï¼‰
    7. ä¸­éƒ¨å½¢æ€ï¼ˆä¸­1/3æ¶¨è·Œï¼‰
    8. å°¾éƒ¨å½¢æ€ï¼ˆå1/3æ¶¨è·Œï¼‰
    """
    try:
        if len(prices) < 6:
            return None
        prices = np.array(prices, dtype=float)
        n = len(prices)
        
        # 1. æ•´ä½“è¶‹åŠ¿æ–¹å‘ (1=æ¶¨, -1=è·Œ)
        trend = 1 if prices[-1] > prices[0] else -1
        
        # 2. æ¶¨è·Œå¹… (å½’ä¸€åŒ–)
        change = (prices[-1] - prices[0]) / (prices[0] + 1e-8)
        change_norm = np.tanh(change * 10)  # æ˜ å°„åˆ°-1~1
        
        # 3. æ³¢åŠ¨ç‡
        returns = np.diff(prices) / (prices[:-1] + 1e-8)
        volatility = np.std(returns) * np.sqrt(252)
        vol_norm = min(volatility / 0.5, 1.0)  # å½’ä¸€åŒ–åˆ°0~1
        
        # 4-5. æœ€é«˜/æœ€ä½ç‚¹ä½ç½® (ç›¸å¯¹ä½ç½®)
        high_pos = np.argmax(prices) / (n - 1)
        low_pos = np.argmin(prices) / (n - 1)
        
        # 6-8. åˆ†æ®µè¶‹åŠ¿
        seg_len = n // 3
        head = (prices[seg_len] - prices[0]) / (prices[0] + 1e-8)
        mid = (prices[2 * seg_len] - prices[seg_len]) / (prices[seg_len] + 1e-8)
        tail = (prices[-1] - prices[2 * seg_len]) / (prices[2 * seg_len] + 1e-8)
        
        return np.array([
            float(trend), change_norm, vol_norm,
            high_pos, low_pos,
            np.tanh(head * 10), np.tanh(mid * 10), np.tanh(tail * 10)
        ])
    except Exception:
        return None


class VisionEngine:
    def __init__(self):
        self.device = torch.device("cpu")
        self.model = None
        self.pool = None
        self.model_mode = None  # "attention" | "cae"

        # 1. ä¼˜å…ˆåŠ è½½ AttentionCAEï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å›é€€åˆ° QuantCAE
        if os.path.exists(ATTENTION_MODEL_PATH):
            if not self._load_attention_model():
                self._load_cae_model()
        else:
            self._load_cae_model()

        self.preprocess = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

        self.index = None
        self.meta_data = []
        self._pixel_cache = {}
        self._edge_cache = {}
        self._data_loader = None

    def _load_attention_model(self):
        try:
            print(f"ğŸ‘ï¸ [VisionEngine] å¯åŠ¨ä¸­... åŠ è½½æ¨¡å‹: AttentionCAE")
            self.model = AttentionCAE(latent_dim=1024, num_attention_heads=8).to(self.device)
            state_dict = torch.load(ATTENTION_MODEL_PATH, map_location=self.device)
            self.model.load_state_dict(state_dict)
            self.model.eval()
            self.use_attention = True
            self.pool = None
            self.model_mode = "attention"
            print(f"âœ… AttentionCAE åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ AttentionCAE æƒé‡åŠ è½½å¤±è´¥: {e}")
            return False

    def _load_cae_model(self):
        try:
            print(f"ğŸ‘ï¸ [VisionEngine] å¯åŠ¨ä¸­... åŠ è½½æ¨¡å‹: QuantCAE (å›é€€æ¨¡å¼)")
            from src.models.autoencoder import QuantCAE
            self.model = QuantCAE().to(self.device)
            if os.path.exists(CAE_MODEL_PATH):
                state_dict = torch.load(CAE_MODEL_PATH, map_location=self.device)
                self.model.load_state_dict(state_dict)
                self.model.eval()
                print(f"âœ… QuantCAE åŠ è½½æˆåŠŸ")
            self.use_attention = False
            self.pool = nn.AdaptiveAvgPool1d(1024)
            self.model_mode = "cae"
            return True
        except Exception as e:
            print(f"âŒ QuantCAE æƒé‡åŠ è½½å¤±è´¥: {e}")
            return False

    def reload_index(self):
        # ä¼˜å…ˆåŠ è½½ AttentionCAE ç´¢å¼•
        index_file = ATTENTION_INDEX_FILE if os.path.exists(ATTENTION_INDEX_FILE) else INDEX_FILE
        meta_file = ATTENTION_META_CSV if os.path.exists(ATTENTION_META_CSV) else META_CSV
        
        if not os.path.exists(index_file):
            print(f"âŒ ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_file}")
            return False

        # ç´¢å¼•ä¸æ¨¡å‹å¯¹é½
        index_mode = "attention" if index_file == ATTENTION_INDEX_FILE else "cae"
        if self.model_mode != index_mode:
            if index_mode == "attention":
                self._load_attention_model()
            else:
                self._load_cae_model()

        print(f"ğŸ“¥ [VisionEngine] åŠ è½½ç´¢å¼•: {os.path.basename(index_file)}")
        try:
            self.index = faiss.read_index(index_file)
        except Exception as e:
            print(f"âŒ FAISS åŠ è½½å¤±è´¥: {e}")
            return False

        if os.path.exists(meta_file):
            df = pd.read_csv(meta_file, dtype=str)
            self.meta_data = df.to_dict('records')
        elif os.path.exists(META_PKL):
            with open(META_PKL, 'rb') as f:
                self.meta_data = pickle.load(f)
        else:
            print(f"âŒ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {meta_file}")
            return False

        print(f"âœ… çŸ¥è¯†åº“å°±ç»ª: {len(self.meta_data)} æ¡è®°å½•")
        return True

    def _image_to_vector(self, img_path):
        try:
            with Image.open(img_path) as img:
                img = img.convert('RGB')
                input_tensor = self.preprocess(img).unsqueeze(0).to(self.device)
            with torch.no_grad():
                if self.use_attention:
                    # AttentionCAE.encode() å·²ç»è¿”å› 1024 ç»´çš„ L2 å½’ä¸€åŒ–å‘é‡
                    feature = self.model.encode(input_tensor)
                    return feature.cpu().numpy().flatten()
                else:
                    # QuantCAE.encode() è¿”å› 50176 ç»´ï¼Œéœ€è¦ pool é™ç»´
                    full_feature = self.model.encode(input_tensor)
                    reduced_feature = self.pool(full_feature.unsqueeze(1)).squeeze(1)
                    return reduced_feature.cpu().numpy().flatten()
        except:
            return None

    def _vector_score_to_similarity(self, score):
        """å°†FAISSè¿”å›åˆ†æ•°ç»Ÿä¸€æ˜ å°„åˆ°0~1"""
        try:
            if self.index is not None and self.index.metric_type == faiss.METRIC_INNER_PRODUCT:
                sim = (float(score) + 1.0) / 2.0
            else:
                sim = 1.0 / (1.0 + max(float(score), 0.0))
            return float(np.clip(sim, 0.0, 1.0))
        except Exception:
            return 0.0

    def _resolve_image_path(self, info_path, symbol, date_str):
        """ä»å…ƒæ•°æ®æˆ–ç›®å½•ä¸­å®šä½å†å²Kçº¿å›¾ç‰‡"""
        if info_path and os.path.exists(info_path):
            return info_path
        date_n = str(date_str).replace("-", "")
        img_bases = [
            os.path.join(PROJECT_ROOT, "data", "images"),
            os.path.join(PROJECT_ROOT, "data", "images_v2"),
        ]
        for img_base in img_bases:
            candidates = [
                os.path.join(img_base, f"{symbol}_{date_n}.png"),
                os.path.join(img_base, symbol, f"{symbol}_{date_n}.png"),
                os.path.join(img_base, symbol, f"{date_n}.png"),
            ]
            for p in candidates:
                if os.path.exists(p):
                    return p
            pattern = os.path.join(img_base, "**", f"*{symbol}*{date_n}*.png")
            matches = glob.glob(pattern, recursive=True)
            if matches:
                return matches[0]
        return None

    def _load_pixel_vector(self, img_path, size=(64, 64)):
        """è½»é‡åƒç´ å‘é‡ï¼ˆç”¨äºè§†è§‰é‡æ’ï¼‰"""
        if not img_path:
            return None
        if img_path in self._pixel_cache:
            return self._pixel_cache[img_path]
        try:
            with Image.open(img_path) as img:
                img = img.convert("L").resize(size)
                arr = np.asarray(img, dtype=np.float32)
            arr = (arr - arr.mean()) / (arr.std() + 1e-6)
            vec = arr.flatten()
            self._pixel_cache[img_path] = vec
            if len(self._pixel_cache) > 500:
                self._pixel_cache.pop(next(iter(self._pixel_cache)))
            return vec
        except Exception:
            return None

    def _cosine_sim(self, a, b):
        if a is None or b is None:
            return None
        denom = (np.linalg.norm(a) * np.linalg.norm(b)) + 1e-8
        return float(np.dot(a, b) / denom)

    def _pearson_corr(self, a, b):
        if a is None or b is None:
            return None
        if len(a) != len(b):
            return None
        try:
            return float(np.corrcoef(a, b)[0, 1])
        except Exception:
            return None

    def _parse_date(self, date_str):
        try:
            return datetime.strptime(str(date_str), "%Y%m%d")
        except Exception:
            try:
                return datetime.strptime(str(date_str), "%Y-%m-%d")
            except Exception:
                return None

    def _load_edge_vector(self, img_path, size=(64, 64)):
        """ç®€å•è¾¹ç¼˜ç‰¹å¾ï¼ˆåƒç´ å·®åˆ†ï¼‰"""
        if not img_path:
            return None
        if img_path in self._edge_cache:
            return self._edge_cache[img_path]
        try:
            with Image.open(img_path) as img:
                img = img.convert("L").resize(size)
                arr = np.asarray(img, dtype=np.float32)
            gx = np.diff(arr, axis=1, prepend=arr[:, :1])
            gy = np.diff(arr, axis=0, prepend=arr[:1, :])
            edge = np.sqrt(gx ** 2 + gy ** 2)
            edge = (edge - edge.mean()) / (edge.std() + 1e-6)
            vec = edge.flatten()
            self._edge_cache[img_path] = vec
            if len(self._edge_cache) > 500:
                self._edge_cache.pop(next(iter(self._edge_cache)))
            return vec
        except Exception:
            return None

    def search_similar_patterns(self, target_img_path, top_k=10, query_prices=None,
                                rerank_with_pixels=True, rerank_top_k=80, max_date: str = None,
                                fast_mode: bool = False, search_k: int = None,
                                max_price_checks: int = None, use_price_features: bool = True):
        """
        ã€æ ¸å¿ƒæ”¹è¿›ã€‘DTWä¸»å¯¼ + è§†è§‰è¾…åŠ©çš„æ··åˆæ£€ç´¢
        
        æ ¸å¿ƒæ€è·¯ï¼š
        1. FAISSåªåšç²—ç­›ï¼ˆè·å–2000+å€™é€‰ï¼‰
        2. DTW + å½¢æ€ç‰¹å¾åšç²¾æ’ï¼ˆçœŸæ­£å†³å®š"åƒä¸åƒ"ï¼‰
        3. æœ€ç»ˆæŒ‰DTWç›¸ä¼¼åº¦æ’åº
        
        Args:
            target_img_path: æŸ¥è¯¢Kçº¿å›¾è·¯å¾„
            top_k: è¿”å›Top-Kç»“æœ
            query_prices: æŸ¥è¯¢çš„ä»·æ ¼åºåˆ—ï¼ˆ20å¤©æ”¶ç›˜ä»·ï¼‰ï¼Œç”¨äºè®¡ç®—DTW
        """
        if self.index is None:
            if not self.reload_index(): return []

        vec = self._image_to_vector(target_img_path)
        if vec is None: return []

        vec = vec.astype('float32').reshape(1, -1)
        faiss.normalize_L2(vec)

        # === å…³é”®æ”¹è¿›1: å¤§å¹…æ‰©å¤§ç²—ç­›èŒƒå›´ï¼ˆä»400â†’2000ï¼‰===
        # å› ä¸ºCNNç‰¹å¾ä¸å¯é ï¼Œéœ€è¦ä»æ›´å¤§èŒƒå›´ä¸­ç”¨DTWç²¾é€‰
        if search_k is None:
            if fast_mode:
                search_k = max(top_k * 50, 500)
            else:
                search_k = max(top_k * 200, 2000)
        if fast_mode:
            use_price_features = False
        D, I = self.index.search(vec, search_k)

        candidates = []
        seen_dates = {}
        ISOLATION_DAYS = 20
        max_dt = self._parse_date(max_date) if max_date else None

        # === ä¼˜åŒ–2: è§†è§‰å€™é€‰ +ï¼ˆå¯é€‰ï¼‰ä»·æ ¼ç›¸å…³æ€§ ===
        # æ³¨æ„ï¼šå¯¹â€œéçƒ­é—¨è‚¡/å†·é—¨æ—¥æœŸâ€ï¼Œåœ¨å¾ªç¯é‡Œé¢‘ç¹æ‹‰å–å†å²æ•°æ®å¾ˆå®¹æ˜“å¤±è´¥ã€‚
        # æˆ‘ä»¬å°†ç›¸å…³æ€§è§†ä¸ºâ€œå¯é€‰å¢å¼ºâ€ï¼šç®—å¾—å‡ºæ¥å°±æå‡æ’åºï¼Œç®—ä¸å‡ºæ¥å°±å›é€€åˆ°çº¯è§†è§‰TopKï¼Œ
        # è¿™æ ·æ‰èƒ½ä¿è¯å¯¹æ¯”å›¾å‡ ä¹ä¸å¯èƒ½ç©ºã€‚
        loader = None
        price_df_cache = {}
        price_checks = 0
        if use_price_features and query_prices is not None and len(query_prices) == 20:
            try:
                if self._data_loader is None:
                    from src.data.data_loader import DataLoader
                    self._data_loader = DataLoader()
                loader = self._data_loader
            except Exception:
                loader = None

        for vector_score, idx in zip(D[0], I[0]):
            if idx >= len(self.meta_data): continue

            info = self.meta_data[idx]
            sym = str(info['symbol']).zfill(6)
            date_str = str(info['date'])

            try:
                current_dt = datetime.strptime(date_str, "%Y%m%d")
            except:
                try:
                    current_dt = datetime.strptime(date_str, "%Y-%m-%d")
                except:
                    continue

            # æ—¶é—´éš”ç¦»æ£€æŸ¥ï¼ˆåŒä¸€è‚¡ç¥¨é—´éš”ï¼‰
            is_conflict = False
            if sym in seen_dates:
                for existing_dt in seen_dates[sym]:
                    if abs((current_dt - existing_dt).days) < ISOLATION_DAYS:
                        is_conflict = True
                        break
            if is_conflict:
                continue

            # ä¸¥æ ¼æ—¶é—´éš”ç¦»ï¼šä¸å…è®¸ä½¿ç”¨æœªæ¥æ•°æ®
            if max_dt and current_dt and current_dt > max_dt:
                continue

            # === ä¼˜åŒ–3: è®¡ç®—ä»·æ ¼åºåˆ—ç›¸å…³æ€§ + DTW + å½¢æ€ç‰¹å¾ï¼ˆå¯é€‰ï¼‰===
            correlation = None
            ret_corr = None
            dtw_sim = None
            feature_sim = None
            match_trend = None
            
            if loader is not None and (max_price_checks is None or price_checks < max_price_checks):
                try:
                    if sym not in price_df_cache:
                        dfp = loader.get_stock_data(sym)
                        if dfp is None or dfp.empty:
                            price_df_cache[sym] = None
                        else:
                            dfp.index = pd.to_datetime(dfp.index)
                            price_df_cache[sym] = dfp
                    else:
                        dfp = price_df_cache[sym]

                    if dfp is not None and (current_dt in dfp.index):
                        loc = dfp.index.get_loc(current_dt)
                        if loc >= 19:
                            match_prices = dfp.iloc[loc - 19: loc + 1]['Close'].values
                            price_checks += 1
                            
                            # A. ä»·æ ¼ç›¸å…³æ€§
                            query_norm = (query_prices - query_prices.mean()) / (query_prices.std() + 1e-8)
                            match_norm = (match_prices - match_prices.mean()) / (match_prices.std() + 1e-8)
                            corr = np.corrcoef(query_norm, match_norm)[0, 1]
                            if not np.isnan(corr):
                                correlation = float(corr)
                            
                            # B. å›æŠ¥åºåˆ—ç›¸å…³
                            q_ret = np.diff(query_prices) / (query_prices[:-1] + 1e-8)
                            m_ret = np.diff(match_prices) / (match_prices[:-1] + 1e-8)
                            q_ret_norm = (q_ret - q_ret.mean()) / (q_ret.std() + 1e-8)
                            m_ret_norm = (m_ret - m_ret.mean()) / (m_ret.std() + 1e-8)
                            corr2 = np.corrcoef(q_ret_norm, m_ret_norm)[0, 1]
                            if not np.isnan(corr2):
                                ret_corr = float(corr2)
                            
                            # C. DTWå½¢æ€ç›¸ä¼¼åº¦ (è·ç¦»è¶Šå°è¶Šç›¸ä¼¼)
                            dtw_dist = _dtw_distance(query_prices, match_prices)
                            dtw_sim = max(0, 1.0 - dtw_dist)  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦
                            
                            # D. å½¢æ€ç‰¹å¾ç›¸ä¼¼åº¦
                            q_feat = _extract_kline_features(query_prices)
                            m_feat = _extract_kline_features(match_prices)
                            if q_feat is not None and m_feat is not None:
                                # è¶‹åŠ¿æ–¹å‘
                                match_trend = m_feat[0]
                                # ç‰¹å¾å‘é‡ä½™å¼¦ç›¸ä¼¼åº¦
                                feat_cos = np.dot(q_feat, m_feat) / (np.linalg.norm(q_feat) * np.linalg.norm(m_feat) + 1e-8)
                                feature_sim = (feat_cos + 1.0) / 2.0
                                
                except Exception:
                    correlation = None

            # === ã€æ ¸å¿ƒæ”¹è¿›ã€‘DTWä¸»å¯¼çš„è¯„åˆ†ç­–ç•¥ ===
            sim_score = self._vector_score_to_similarity(vector_score)

            # ç›¸å…³æ€§å½’ä¸€åŒ–
            corr_norm = None
            if correlation is not None:
                corr_norm = (float(correlation) + 1.0) / 2.0
                corr_norm = min(max(corr_norm, 0.0), 1.0)
                if ret_corr is not None:
                    ret_norm = (float(ret_corr) + 1.0) / 2.0
                    corr_norm = 0.5 * corr_norm + 0.5 * ret_norm
            
            # ã€å…³é”®ã€‘DTWä¸»å¯¼è¯„åˆ†ï¼šDTW 50% + ç›¸å…³æ€§ 30% + å½¢æ€ 15% + è§†è§‰ 5%
            # å¦‚æœæ²¡æœ‰ä»·æ ¼æ•°æ®ï¼Œåˆ™å›é€€åˆ°çº¯è§†è§‰
            if dtw_sim is not None:
                dtw_score = dtw_sim
                feat_score = feature_sim if feature_sim is not None else 0.5
                corr_score = corr_norm if corr_norm is not None else 0.5
                combined_score = 0.50 * dtw_score + 0.30 * corr_score + 0.15 * feat_score + 0.05 * sim_score
            else:
                combined_score = sim_score * 0.3 if use_price_features else sim_score

            candidates.append({
                "symbol": sym,
                "date": date_str,
                "score": float(combined_score),
                "vector_score": float(vector_score),
                "correlation": (None if correlation is None else float(correlation)),
                "ret_corr": (None if ret_corr is None else float(ret_corr)),
                "dtw_sim": (None if dtw_sim is None else float(dtw_sim)),
                "feature_sim": (None if feature_sim is None else float(feature_sim)),
                "match_trend": match_trend,
                "sim_score": float(sim_score),
                "corr_norm": (None if corr_norm is None else float(corr_norm)),
                "path": info.get("path")
            })

            seen_dates.setdefault(sym, []).append(current_dt)
            
            # ã€æ€§èƒ½ä¼˜åŒ–ã€‘å·²æ”¶é›†è¶³å¤Ÿé«˜è´¨é‡å€™é€‰æ—¶æå‰ç»ˆæ­¢
            high_quality = [c for c in candidates if c.get("dtw_sim") is not None and c["dtw_sim"] > 0.8]
            if len(high_quality) >= top_k * 3:
                break

        # === ã€æ ¸å¿ƒæ”¹è¿›ã€‘DTWä¸»å¯¼çš„æœ€ç»ˆæ’åº ===
        if query_prices is not None and len(query_prices) >= 2:
            # Step 1: è¶‹åŠ¿æ–¹å‘ç¡¬çº¦æŸï¼ˆå¿…é¡»åŒæ¶¨åŒè·Œï¼‰
            query_trend = 1 if query_prices[-1] > query_prices[0] else -1
            
            # åªä¿ç•™è¶‹åŠ¿æ–¹å‘ä¸€è‡´çš„å€™é€‰
            trend_matched = [
                c for c in candidates 
                if c.get("match_trend") is None or c.get("match_trend") == query_trend
            ]
            
            # Step 2: ä¼˜å…ˆé€‰æ‹©æœ‰DTWåˆ†æ•°çš„å€™é€‰
            dtw_candidates = [c for c in trend_matched if c.get("dtw_sim") is not None]
            no_dtw_candidates = [c for c in trend_matched if c.get("dtw_sim") is None]
            
            # Step 3: DTWå€™é€‰æŒ‰DTWç›¸ä¼¼åº¦æ’åºï¼ˆè¿™æ˜¯å…³é”®ï¼ï¼‰
            dtw_candidates.sort(key=lambda x: x.get("dtw_sim", 0), reverse=True)
            
            # Step 4: æ— DTWå€™é€‰æŒ‰ç›¸å…³æ€§æ’åº
            no_dtw_candidates.sort(key=lambda x: x.get("correlation", 0) or 0, reverse=True)
            
            # Step 5: åˆå¹¶ï¼ˆDTWä¼˜å…ˆï¼‰
            candidates = dtw_candidates + no_dtw_candidates
            
            # Step 6: æœ€ç»ˆè¯„åˆ†ï¼ˆç”¨äºæ˜¾ç¤ºï¼Œä½†æ’åºå·²ç»æŒ‰DTWå®Œæˆï¼‰
            for c in candidates:
                dtw = c.get("dtw_sim", 0)
                corr = c.get("correlation", 0) or 0
                corr_norm = (corr + 1.0) / 2.0
                feat = c.get("feature_sim", 0.5)
                # æœ€ç»ˆåˆ†æ•°ï¼ˆä»…ä¾›æ˜¾ç¤ºï¼‰
                c["score"] = 0.60 * dtw + 0.25 * corr_norm + 0.15 * feat if dtw > 0 else corr_norm * 0.5
        
        else:
            # æ— ä»·æ ¼åºåˆ—æ—¶ï¼Œå›é€€åˆ°çº¯è§†è§‰æ’åº
            candidates.sort(key=lambda x: x.get("sim_score", 0), reverse=True)

        # è¿”å›Top-K
        return candidates[:top_k]

    def generate_attention_heatmap(self, img_path, save_path=None, head_idx: int = 0, mode: str = "single"):
        """
        ç”Ÿæˆæ³¨æ„åŠ›çƒ­åŠ›å›¾ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒæ³¨æ„åŠ›æƒé‡ï¼‰
        """
        try:
            from src.utils.attention_visualizer import AttentionVisualizer
            if not hasattr(self.model, "get_attention_weights"):
                return None
            # è¯»å–å¹¶é¢„å¤„ç†
            img = Image.open(img_path).convert('RGB')
            input_tensor = self.preprocess(img)
            visualizer = AttentionVisualizer(self.model, device=str(self.device))
            if mode == "all":
                fig = visualizer.visualize_multi_head_attention(
                    input_tensor, query_pos=(7, 7), save_path=save_path
                )
            else:
                fig = visualizer.visualize_single_attention(
                    input_tensor, head_idx=head_idx, query_pos=(7, 7), save_path=save_path
                )
            return save_path
        except Exception:
            return None

    def search_multi_scale_patterns(self, img_paths: dict, top_k=10, weights=None, query_prices=None,
                                    rerank_with_pixels=True, rerank_top_k=80, max_date: str = None):
        """
        å¤šå°ºåº¦æ£€ç´¢ï¼šæ—¥/å‘¨/æœˆå›¾åƒåˆ†åˆ«æ£€ç´¢ï¼Œå†åŠ æƒèåˆ
        """
        if self.index is None:
            if not self.reload_index():
                return []
        if not img_paths:
            return []
        if weights is None:
            weights = {"daily": 0.6, "weekly": 0.3, "monthly": 0.1}

        merged = {}
        max_dt = self._parse_date(max_date) if max_date else None
        for scale, path in img_paths.items():
            vec = self._image_to_vector(path)
            if vec is None:
                continue
            vec = vec.astype('float32').reshape(1, -1)
            faiss.normalize_L2(vec)
            search_k = max(top_k * 10, 200)
            D, I = self.index.search(vec, search_k)
            for vector_score, idx in zip(D[0], I[0]):
                if idx >= len(self.meta_data):
                    continue
                info = self.meta_data[idx]
                sym = str(info['symbol']).zfill(6)
                date_str = str(info['date'])
                dt = self._parse_date(date_str)
                if max_dt and dt and dt > max_dt:
                    continue
                key = (sym, date_str)
                # è·ç¦»è½¬ç›¸ä¼¼åº¦
                sim = self._vector_score_to_similarity(vector_score)
                w = weights.get(scale, 0.0)
                merged[key] = merged.get(key, 0.0) + sim * w

        # ç›¸å…³æ€§å¢å¼ºï¼ˆä»…å¯¹æ—¥çº¿ä½¿ç”¨ï¼‰
        candidates = []
        for (sym, date_str), score in merged.items():
            candidates.append({"symbol": sym, "date": date_str, "score": float(score), "path": None})

        # åƒç´ é‡æ’ï¼ˆä½¿ç”¨æ—¥çº¿Queryï¼‰
        if rerank_with_pixels and candidates and img_paths.get("daily"):
            q_vec = self._load_pixel_vector(img_paths.get("daily"))
            if q_vec is not None:
                q_edge = self._load_edge_vector(img_paths.get("daily"))
                for c in candidates[:min(len(candidates), rerank_top_k)]:
                    img_path = self._resolve_image_path(None, c["symbol"], c["date"])
                    v = self._load_pixel_vector(img_path)
                    e = self._load_edge_vector(img_path)
                    pix_cos = self._cosine_sim(q_vec, v)
                    pix_corr = self._pearson_corr(q_vec, v)
                    edge_cos = self._cosine_sim(q_edge, e) if q_edge is not None else None
                    pix_cos = 0.0 if pix_cos is None else pix_cos
                    pix_corr = 0.0 if pix_corr is None else pix_corr
                    edge_cos = 0.0 if edge_cos is None else edge_cos
                    pix_norm = (pix_cos + 1.0) / 2.0
                    pix_corr_norm = (pix_corr + 1.0) / 2.0
                    edge_norm = (edge_cos + 1.0) / 2.0
                    visual_sim = 0.5 * pix_norm + 0.3 * pix_corr_norm + 0.2 * edge_norm
                    c["pixel_sim"] = visual_sim
                    c["edge_sim"] = edge_norm
                    c["score"] = 0.7 * c["score"] + 0.3 * visual_sim
        candidates.sort(key=lambda x: x["score"], reverse=True)

        # æ—¶é—´éš”ç¦»ï¼ˆé¿å…åŒä¸€è‚¡ç¥¨ç›¸é‚»æ—¥æœŸï¼‰
        ISOLATION_DAYS = 20
        isolated = []
        seen_dates = {}
        for c in candidates:
            sym = str(c.get("symbol", "")).zfill(6)
            dt = self._parse_date(c.get("date"))
            if dt is None:
                continue
            conflict = False
            if sym in seen_dates:
                for d in seen_dates[sym]:
                    if abs((dt - d).days) < ISOLATION_DAYS:
                        conflict = True
                        break
            if conflict:
                continue
            isolated.append(c)
            seen_dates.setdefault(sym, []).append(dt)
            if len(isolated) >= top_k:
                break

        return isolated if isolated else candidates[:top_k]


if __name__ == "__main__":
    if PROJECT_ROOT not in sys.path: sys.path.insert(0, PROJECT_ROOT)
    v = VisionEngine()
    v.reload_index()
    print("Vision Engine Ready")