import os
import sys
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import faiss
import pickle
import glob
import pandas as pd
import numpy as np
from datetime import datetime

# === 1. åŸºç¡€é…ç½® ===
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'
os.environ['OMP_NUM_THREADS'] = '1'

# === 2. è·¯å¾„é…ç½® ===
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(CURRENT_DIR))
# ä¼˜å…ˆä½¿ç”¨ AttentionCAEï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å›é€€åˆ° QuantCAE
ATTENTION_MODEL_PATH = os.path.join(PROJECT_ROOT, "data", "models", "attention_cae_best.pth")
CAE_MODEL_PATH = os.path.join(PROJECT_ROOT, "data", "models", "cae_best.pth")
# ç´¢å¼•æ–‡ä»¶è·¯å¾„ï¼ˆä¼˜å…ˆç”¨æ–°ç´¢å¼•ï¼‰
ATTENTION_INDEX_FILE = os.path.join(PROJECT_ROOT, "data", "indices", "cae_faiss_attention.bin")
ATTENTION_META_CSV = os.path.join(PROJECT_ROOT, "data", "indices", "meta_data_attention.csv")
INDEX_FILE = os.path.join(PROJECT_ROOT, "data", "indices", "cae_faiss.bin")
META_CSV = os.path.join(PROJECT_ROOT, "data", "indices", "meta_data.csv")
META_PKL = os.path.join(PROJECT_ROOT, "data", "indices", "meta.pkl")

if PROJECT_ROOT not in sys.path:
    sys.path.append(PROJECT_ROOT)
from src.models.attention_cae import AttentionCAE


class VisionEngine:
    def __init__(self):
        self.device = torch.device("cpu")
        self.model = None
        self.pool = None
        self.model_mode = None  # "attention" | "cae"

        # 1. ä¼˜å…ˆåŠ è½½ AttentionCAEï¼Œå¦‚æœä¸å­˜åœ¨åˆ™å›é€€åˆ° QuantCAE
        if os.path.exists(ATTENTION_MODEL_PATH):
            if not self._load_attention_model():
                self._load_cae_model()
        else:
            self._load_cae_model()

        self.preprocess = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])

        self.index = None
        self.meta_data = []
        self._pixel_cache = {}
        self._edge_cache = {}
        self._data_loader = None

    def _load_attention_model(self):
        try:
            print(f"ğŸ‘ï¸ [VisionEngine] å¯åŠ¨ä¸­... åŠ è½½æ¨¡å‹: AttentionCAE")
            self.model = AttentionCAE(latent_dim=1024, num_attention_heads=8).to(self.device)
            state_dict = torch.load(ATTENTION_MODEL_PATH, map_location=self.device)
            self.model.load_state_dict(state_dict)
            self.model.eval()
            self.use_attention = True
            self.pool = None
            self.model_mode = "attention"
            print(f"âœ… AttentionCAE åŠ è½½æˆåŠŸ")
            return True
        except Exception as e:
            print(f"âŒ AttentionCAE æƒé‡åŠ è½½å¤±è´¥: {e}")
            return False

    def _load_cae_model(self):
        try:
            print(f"ğŸ‘ï¸ [VisionEngine] å¯åŠ¨ä¸­... åŠ è½½æ¨¡å‹: QuantCAE (å›é€€æ¨¡å¼)")
            from src.models.autoencoder import QuantCAE
            self.model = QuantCAE().to(self.device)
            if os.path.exists(CAE_MODEL_PATH):
                state_dict = torch.load(CAE_MODEL_PATH, map_location=self.device)
                self.model.load_state_dict(state_dict)
                self.model.eval()
                print(f"âœ… QuantCAE åŠ è½½æˆåŠŸ")
            self.use_attention = False
            self.pool = nn.AdaptiveAvgPool1d(1024)
            self.model_mode = "cae"
            return True
        except Exception as e:
            print(f"âŒ QuantCAE æƒé‡åŠ è½½å¤±è´¥: {e}")
            return False

    def reload_index(self):
        # ä¼˜å…ˆåŠ è½½ AttentionCAE ç´¢å¼•
        index_file = ATTENTION_INDEX_FILE if os.path.exists(ATTENTION_INDEX_FILE) else INDEX_FILE
        meta_file = ATTENTION_META_CSV if os.path.exists(ATTENTION_META_CSV) else META_CSV
        
        if not os.path.exists(index_file):
            print(f"âŒ ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨: {index_file}")
            return False

        # ç´¢å¼•ä¸æ¨¡å‹å¯¹é½
        index_mode = "attention" if index_file == ATTENTION_INDEX_FILE else "cae"
        if self.model_mode != index_mode:
            if index_mode == "attention":
                self._load_attention_model()
            else:
                self._load_cae_model()

        print(f"ğŸ“¥ [VisionEngine] åŠ è½½ç´¢å¼•: {os.path.basename(index_file)}")
        try:
            self.index = faiss.read_index(index_file)
        except Exception as e:
            print(f"âŒ FAISS åŠ è½½å¤±è´¥: {e}")
            return False

        if os.path.exists(meta_file):
            df = pd.read_csv(meta_file, dtype=str)
            self.meta_data = df.to_dict('records')
        elif os.path.exists(META_PKL):
            with open(META_PKL, 'rb') as f:
                self.meta_data = pickle.load(f)
        else:
            print(f"âŒ å…ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {meta_file}")
            return False

        print(f"âœ… çŸ¥è¯†åº“å°±ç»ª: {len(self.meta_data)} æ¡è®°å½•")
        return True

    def _image_to_vector(self, img_path):
        try:
            img = Image.open(img_path).convert('RGB')
            input_tensor = self.preprocess(img).unsqueeze(0).to(self.device)
            with torch.no_grad():
                if self.use_attention:
                    # AttentionCAE.encode() å·²ç»è¿”å› 1024 ç»´çš„ L2 å½’ä¸€åŒ–å‘é‡
                    feature = self.model.encode(input_tensor)
                    return feature.cpu().numpy().flatten()
                else:
                    # QuantCAE.encode() è¿”å› 50176 ç»´ï¼Œéœ€è¦ pool é™ç»´
                full_feature = self.model.encode(input_tensor)
                reduced_feature = self.pool(full_feature.unsqueeze(1)).squeeze(1)
                return reduced_feature.cpu().numpy().flatten()
        except:
            return None

    def _vector_score_to_similarity(self, score):
        """å°†FAISSè¿”å›åˆ†æ•°ç»Ÿä¸€æ˜ å°„åˆ°0~1"""
        try:
            if self.index is not None and self.index.metric_type == faiss.METRIC_INNER_PRODUCT:
                sim = (float(score) + 1.0) / 2.0
            else:
                sim = 1.0 / (1.0 + max(float(score), 0.0))
            return float(np.clip(sim, 0.0, 1.0))
        except Exception:
            return 0.0

    def _resolve_image_path(self, info_path, symbol, date_str):
        """ä»å…ƒæ•°æ®æˆ–ç›®å½•ä¸­å®šä½å†å²Kçº¿å›¾ç‰‡"""
        if info_path and os.path.exists(info_path):
            return info_path
        img_base = os.path.join(PROJECT_ROOT, "data", "images")
        date_n = str(date_str).replace("-", "")
        candidates = [
            os.path.join(img_base, f"{symbol}_{date_n}.png"),
            os.path.join(img_base, symbol, f"{symbol}_{date_n}.png"),
            os.path.join(img_base, symbol, f"{date_n}.png"),
        ]
        for p in candidates:
            if os.path.exists(p):
                return p
        pattern = os.path.join(img_base, "**", f"*{symbol}*{date_n}*.png")
        matches = glob.glob(pattern, recursive=True)
        return matches[0] if matches else None

    def _load_pixel_vector(self, img_path, size=(64, 64)):
        """è½»é‡åƒç´ å‘é‡ï¼ˆç”¨äºè§†è§‰é‡æ’ï¼‰"""
        if not img_path:
            return None
        if img_path in self._pixel_cache:
            return self._pixel_cache[img_path]
        try:
            img = Image.open(img_path).convert("L").resize(size)
            arr = np.asarray(img, dtype=np.float32)
            arr = (arr - arr.mean()) / (arr.std() + 1e-6)
            vec = arr.flatten()
            self._pixel_cache[img_path] = vec
            if len(self._pixel_cache) > 500:
                self._pixel_cache.pop(next(iter(self._pixel_cache)))
            return vec
        except Exception:
            return None

    def _cosine_sim(self, a, b):
        if a is None or b is None:
            return None
        denom = (np.linalg.norm(a) * np.linalg.norm(b)) + 1e-8
        return float(np.dot(a, b) / denom)

    def _pearson_corr(self, a, b):
        if a is None or b is None:
            return None
        if len(a) != len(b):
            return None
        try:
            return float(np.corrcoef(a, b)[0, 1])
        except Exception:
            return None

    def _parse_date(self, date_str):
        try:
            return datetime.strptime(str(date_str), "%Y%m%d")
        except Exception:
            try:
                return datetime.strptime(str(date_str), "%Y-%m-%d")
            except Exception:
                return None

    def _load_edge_vector(self, img_path, size=(64, 64)):
        """ç®€å•è¾¹ç¼˜ç‰¹å¾ï¼ˆåƒç´ å·®åˆ†ï¼‰"""
        if not img_path:
            return None
        if img_path in self._edge_cache:
            return self._edge_cache[img_path]
        try:
            img = Image.open(img_path).convert("L").resize(size)
            arr = np.asarray(img, dtype=np.float32)
            gx = np.diff(arr, axis=1, prepend=arr[:, :1])
            gy = np.diff(arr, axis=0, prepend=arr[:1, :])
            edge = np.sqrt(gx ** 2 + gy ** 2)
            edge = (edge - edge.mean()) / (edge.std() + 1e-6)
            vec = edge.flatten()
            self._edge_cache[img_path] = vec
            if len(self._edge_cache) > 500:
                self._edge_cache.pop(next(iter(self._edge_cache)))
            return vec
        except Exception:
            return None

    def search_similar_patterns(self, target_img_path, top_k=10, query_prices=None,
                                rerank_with_pixels=True, rerank_top_k=80):
        """
        æ··åˆæœç´¢ï¼šè§†è§‰ç‰¹å¾ + ä»·æ ¼åºåˆ—ç›¸å…³æ€§
        
        Args:
            target_img_path: æŸ¥è¯¢Kçº¿å›¾è·¯å¾„
            top_k: è¿”å›Top-Kç»“æœ
            query_prices: æŸ¥è¯¢çš„ä»·æ ¼åºåˆ—ï¼ˆ20å¤©æ”¶ç›˜ä»·ï¼‰ï¼Œç”¨äºè®¡ç®—ç›¸å…³æ€§
        """
        if self.index is None:
            if not self.reload_index(): return []

        vec = self._image_to_vector(target_img_path)
        if vec is None: return []

        vec = vec.astype('float32').reshape(1, -1)
        faiss.normalize_L2(vec)

        # === ä¼˜åŒ–1: æ‰©å¤§æœç´¢èŒƒå›´ï¼Œè·å–æ›´å¤šå€™é€‰ ===
        search_k = max(top_k * 20, 400)  # ä»æ›´å¤§å€™é€‰ä¸­ç­›é€‰
        D, I = self.index.search(vec, search_k)

        candidates = []
        seen_dates = {}
        ISOLATION_DAYS = 20

        # === ä¼˜åŒ–2: è§†è§‰å€™é€‰ +ï¼ˆå¯é€‰ï¼‰ä»·æ ¼ç›¸å…³æ€§ ===
        # æ³¨æ„ï¼šå¯¹â€œéçƒ­é—¨è‚¡/å†·é—¨æ—¥æœŸâ€ï¼Œåœ¨å¾ªç¯é‡Œé¢‘ç¹æ‹‰å–å†å²æ•°æ®å¾ˆå®¹æ˜“å¤±è´¥ã€‚
        # æˆ‘ä»¬å°†ç›¸å…³æ€§è§†ä¸ºâ€œå¯é€‰å¢å¼ºâ€ï¼šç®—å¾—å‡ºæ¥å°±æå‡æ’åºï¼Œç®—ä¸å‡ºæ¥å°±å›é€€åˆ°çº¯è§†è§‰TopKï¼Œ
        # è¿™æ ·æ‰èƒ½ä¿è¯å¯¹æ¯”å›¾å‡ ä¹ä¸å¯èƒ½ç©ºã€‚
        loader = None
        price_df_cache = {}
        if query_prices is not None and len(query_prices) == 20:
            try:
                if self._data_loader is None:
                    from src.data.data_loader import DataLoader
                    self._data_loader = DataLoader()
                loader = self._data_loader
            except Exception:
                loader = None

        for vector_score, idx in zip(D[0], I[0]):
            if idx >= len(self.meta_data): continue

            info = self.meta_data[idx]
            sym = str(info['symbol']).zfill(6)
            date_str = str(info['date'])

            try:
                current_dt = datetime.strptime(date_str, "%Y%m%d")
            except:
                try:
                    current_dt = datetime.strptime(date_str, "%Y-%m-%d")
                except:
                    continue

            # æ—¶é—´éš”ç¦»æ£€æŸ¥
            is_conflict = False
            if sym in seen_dates:
                for existing_dt in seen_dates[sym]:
                    if abs((current_dt - existing_dt).days) < ISOLATION_DAYS:
                        is_conflict = True
                        break
            if is_conflict:
                continue

            # === ä¼˜åŒ–3: è®¡ç®—ä»·æ ¼åºåˆ—ç›¸å…³æ€§ï¼ˆå¯é€‰ï¼‰===
            correlation = None
            ret_corr = None
            if loader is not None:
                try:
                    if sym not in price_df_cache:
                        dfp = loader.get_stock_data(sym)
                        if dfp is None or dfp.empty:
                            price_df_cache[sym] = None
                        else:
                            dfp.index = pd.to_datetime(dfp.index)
                            price_df_cache[sym] = dfp
                    else:
                        dfp = price_df_cache[sym]

                    if dfp is not None and (current_dt in dfp.index):
                        loc = dfp.index.get_loc(current_dt)
                        if loc >= 19:
                            match_prices = dfp.iloc[loc - 19: loc + 1]['Close'].values
                            query_norm = (query_prices - query_prices.mean()) / (query_prices.std() + 1e-8)
                            match_norm = (match_prices - match_prices.mean()) / (match_prices.std() + 1e-8)
                            corr = np.corrcoef(query_norm, match_norm)[0, 1]
                            if not np.isnan(corr):
                                correlation = float(corr)
                            # å½¢æ€å›æŠ¥ç›¸å…³ï¼ˆå·®åˆ†ï¼‰
                            q_ret = np.diff(query_prices) / (query_prices[:-1] + 1e-8)
                            m_ret = np.diff(match_prices) / (match_prices[:-1] + 1e-8)
                            q_ret = (q_ret - q_ret.mean()) / (q_ret.std() + 1e-8)
                            m_ret = (m_ret - m_ret.mean()) / (m_ret.std() + 1e-8)
                            corr2 = np.corrcoef(q_ret, m_ret)[0, 1]
                            if not np.isnan(corr2):
                                ret_corr = float(corr2)
                except Exception:
                    correlation = None

            # === ä¼˜åŒ–4: è¯„åˆ†ç­–ç•¥ï¼ˆç›¸ä¼¼åº¦æ ¡å‡† + ç›¸å…³æ€§å¢å¼ºï¼‰===
            sim_score = self._vector_score_to_similarity(vector_score)

            corr_norm = None
            if correlation is None:
                final_score = sim_score
            else:
                # ç›¸å…³æ€§å½’ä¸€åŒ–åˆ° 0~1
                corr_norm = (float(correlation) + 1.0) / 2.0
                corr_norm = min(max(corr_norm, 0.0), 1.0)
                # å åŠ å›æŠ¥ç›¸å…³
                if ret_corr is not None:
                    ret_norm = (float(ret_corr) + 1.0) / 2.0
                    corr_norm = 0.6 * corr_norm + 0.4 * ret_norm
                final_score = 0.7 * sim_score + 0.3 * corr_norm

            candidates.append({
                "symbol": sym,
                "date": date_str,
                "score": float(final_score),
                "vector_score": float(vector_score),
                "correlation": (None if correlation is None else float(correlation)),
                "ret_corr": (None if ret_corr is None else float(ret_corr)),
                "sim_score": float(sim_score),
                "corr_norm": (None if corr_norm is None else float(corr_norm)),
                "path": info.get("path")
            })

            seen_dates.setdefault(sym, []).append(current_dt)

        # === è§†è§‰é‡æ’ï¼šåƒç´ çº§ç›¸ä¼¼åº¦å…œåº•ï¼ˆæå‡â€œè‚‰çœ¼ç›¸ä¼¼â€æ•ˆæœï¼‰ ===
        if rerank_with_pixels and candidates:
            q_vec = self._load_pixel_vector(target_img_path)
            if q_vec is not None:
                q_edge = self._load_edge_vector(target_img_path)
                for c in candidates[:min(len(candidates), rerank_top_k)]:
                    img_path = self._resolve_image_path(c.get("path"), c["symbol"], c["date"])
                    v = self._load_pixel_vector(img_path)
                    e = self._load_edge_vector(img_path)
                    pix_cos = self._cosine_sim(q_vec, v)
                    pix_corr = self._pearson_corr(q_vec, v)
                    edge_cos = self._cosine_sim(q_edge, e) if q_edge is not None else None
                    pix_cos = 0.0 if pix_cos is None else pix_cos
                    pix_corr = 0.0 if pix_corr is None else pix_corr
                    edge_cos = 0.0 if edge_cos is None else edge_cos
                    pix_norm = (pix_cos + 1.0) / 2.0
                    pix_corr_norm = (pix_corr + 1.0) / 2.0
                    edge_norm = (edge_cos + 1.0) / 2.0
                    visual_sim = 0.5 * pix_norm + 0.3 * pix_corr_norm + 0.2 * edge_norm
                    corr = c.get("corr_norm")
                    corr_score = 0.5 if corr is None else corr
                    c["pixel_sim"] = visual_sim
                    c["edge_sim"] = edge_norm
                    c["score"] = 0.45 * c.get("sim_score", 0) + 0.35 * visual_sim + 0.20 * corr_score

        # === ä¼˜åŒ–6: å¼ºç›¸å…³æ€§è¿‡æ»¤ (Strict Filter) & é‡æ’åº ===
        # åªæœ‰å½“åŸå§‹ç›¸å…³æ€§è¾ƒé«˜æ—¶ï¼Œæ‰è®¤ä¸ºè§†è§‰â€œåƒâ€ï¼ˆè¶‹åŠ¿ä¸€è‡´ï¼‰ã€‚
        # å¦‚æœ embedding ç›¸ä¼¼ä½†ç›¸å…³æ€§å¾ˆä½ï¼Œè¯´æ˜åªæ˜¯éœ‡è¡å¹…åº¦åƒä½†èµ°åŠ¿ç›¸åï¼Œç”¨æˆ·ä¼šè§‰å¾—â€œä¸åƒâ€ã€‚
        if query_prices is not None:
            # 1. è¿‡æ»¤ï¼šä¿ç•™ç›¸å…³æ€§ > 0.5 æˆ– å›æŠ¥ç›¸å…³ > 0.4 çš„ç»“æœ
            #    (å¦‚æœè¿‡æ»¤åå¤ªå°‘ï¼Œåˆ™æ”¾å®½æ ‡å‡†)
            strict_candidates = [
                c for c in candidates 
                if (c.get("correlation") is not None and c["correlation"] > 0.5) 
                or (c.get("ret_corr") is not None and c["ret_corr"] > 0.4)
            ]
            
            if len(strict_candidates) >= top_k:
                candidates = strict_candidates
            
            # 2. é‡æ’åºï¼šæ˜¾è‘—æå‡ç›¸å…³æ€§æƒé‡ï¼Œè®©èµ°åŠ¿æ›´ä¸€è‡´çš„æ’å‰é¢
            #    New Score = 0.4 * Sim + 0.4 * Corr + 0.2 * Pixel
            for c in candidates:
                s = c.get("sim_score", 0)
                corr = c.get("corr_norm", 0.5)
                pix = c.get("pixel_sim", s) # fallback to sim if pixel not calc
                c["score"] = 0.4 * s + 0.4 * corr + 0.2 * pix
                
            candidates.sort(key=lambda x: x['score'], reverse=True)

        # è¿”å›Top-K
        return candidates[:top_k]

    def generate_attention_heatmap(self, img_path, save_path=None, head_idx: int = 0, mode: str = "single"):
        """
        ç”Ÿæˆæ³¨æ„åŠ›çƒ­åŠ›å›¾ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒæ³¨æ„åŠ›æƒé‡ï¼‰
        """
        try:
            from src.utils.attention_visualizer import AttentionVisualizer
            if not hasattr(self.model, "get_attention_weights"):
                return None
            # è¯»å–å¹¶é¢„å¤„ç†
            img = Image.open(img_path).convert('RGB')
            input_tensor = self.preprocess(img)
            visualizer = AttentionVisualizer(self.model, device=str(self.device))
            if mode == "all":
                fig = visualizer.visualize_multi_head_attention(
                    input_tensor, query_pos=(7, 7), save_path=save_path
                )
            else:
                fig = visualizer.visualize_single_attention(
                    input_tensor, head_idx=head_idx, query_pos=(7, 7), save_path=save_path
                )
            return save_path
        except Exception:
            return None

    def search_multi_scale_patterns(self, img_paths: dict, top_k=10, weights=None, query_prices=None,
                                    rerank_with_pixels=True, rerank_top_k=80):
        """
        å¤šå°ºåº¦æ£€ç´¢ï¼šæ—¥/å‘¨/æœˆå›¾åƒåˆ†åˆ«æ£€ç´¢ï¼Œå†åŠ æƒèåˆ
        """
        if self.index is None:
            if not self.reload_index():
                return []
        if not img_paths:
            return []
        if weights is None:
            weights = {"daily": 0.6, "weekly": 0.3, "monthly": 0.1}

        merged = {}
        for scale, path in img_paths.items():
            vec = self._image_to_vector(path)
            if vec is None:
                continue
            vec = vec.astype('float32').reshape(1, -1)
            faiss.normalize_L2(vec)
            search_k = max(top_k * 10, 200)
            D, I = self.index.search(vec, search_k)
            for vector_score, idx in zip(D[0], I[0]):
                if idx >= len(self.meta_data):
                    continue
                info = self.meta_data[idx]
                sym = str(info['symbol']).zfill(6)
                date_str = str(info['date'])
                key = (sym, date_str)
                # è·ç¦»è½¬ç›¸ä¼¼åº¦
                sim = self._vector_score_to_similarity(vector_score)
                w = weights.get(scale, 0.0)
                merged[key] = merged.get(key, 0.0) + sim * w

        # ç›¸å…³æ€§å¢å¼ºï¼ˆä»…å¯¹æ—¥çº¿ä½¿ç”¨ï¼‰
        candidates = []
        for (sym, date_str), score in merged.items():
            candidates.append({"symbol": sym, "date": date_str, "score": float(score), "path": None})

        # åƒç´ é‡æ’ï¼ˆä½¿ç”¨æ—¥çº¿Queryï¼‰
        if rerank_with_pixels and candidates and img_paths.get("daily"):
            q_vec = self._load_pixel_vector(img_paths.get("daily"))
            if q_vec is not None:
                q_edge = self._load_edge_vector(img_paths.get("daily"))
                for c in candidates[:min(len(candidates), rerank_top_k)]:
                    img_path = self._resolve_image_path(None, c["symbol"], c["date"])
                    v = self._load_pixel_vector(img_path)
                    e = self._load_edge_vector(img_path)
                    pix_cos = self._cosine_sim(q_vec, v)
                    pix_corr = self._pearson_corr(q_vec, v)
                    edge_cos = self._cosine_sim(q_edge, e) if q_edge is not None else None
                    pix_cos = 0.0 if pix_cos is None else pix_cos
                    pix_corr = 0.0 if pix_corr is None else pix_corr
                    edge_cos = 0.0 if edge_cos is None else edge_cos
                    pix_norm = (pix_cos + 1.0) / 2.0
                    pix_corr_norm = (pix_corr + 1.0) / 2.0
                    edge_norm = (edge_cos + 1.0) / 2.0
                    visual_sim = 0.5 * pix_norm + 0.3 * pix_corr_norm + 0.2 * edge_norm
                    c["pixel_sim"] = visual_sim
                    c["edge_sim"] = edge_norm
                    c["score"] = 0.7 * c["score"] + 0.3 * visual_sim
        candidates.sort(key=lambda x: x["score"], reverse=True)

        # æ—¶é—´éš”ç¦»ï¼ˆé¿å…åŒä¸€è‚¡ç¥¨ç›¸é‚»æ—¥æœŸï¼‰
        ISOLATION_DAYS = 20
        isolated = []
        seen_dates = {}
        for c in candidates:
            sym = str(c.get("symbol", "")).zfill(6)
            dt = self._parse_date(c.get("date"))
            if dt is None:
                continue
            conflict = False
            if sym in seen_dates:
                for d in seen_dates[sym]:
                    if abs((dt - d).days) < ISOLATION_DAYS:
                        conflict = True
                        break
            if conflict:
                continue
            isolated.append(c)
            seen_dates.setdefault(sym, []).append(dt)
            if len(isolated) >= top_k:
                break

        return isolated if isolated else candidates[:top_k]


if __name__ == "__main__":
    if PROJECT_ROOT not in sys.path: sys.path.insert(0, PROJECT_ROOT)
    v = VisionEngine()
    v.reload_index()
    print("Vision Engine Ready")