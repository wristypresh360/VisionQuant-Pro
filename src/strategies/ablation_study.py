"""
æ¶ˆèå®éªŒæ¡†æ¶ (Ablation Study Framework)

ç”¨äºç³»ç»Ÿæ€§åœ°è¯„ä¼°VisionQuantå„ä¸ªç»„ä»¶çš„è´¡çŒ®ï¼š
1. Self-Attentionæ¨¡å—çš„å½±å“
2. ä»·æ ¼ç›¸å…³æ€§è¿‡æ»¤çš„å½±å“
3. æ—¶é—´éš”ç¦»(NMS)çš„å½±å“
4. ä¸åŒç‰¹å¾æå–å™¨çš„å¯¹æ¯”
5. ä¸åŒæ³¨æ„åŠ›å¤´æ•°çš„å½±å“
6. ä¸åŒç‰¹å¾ç»´åº¦çš„å¯¹æ¯”

Author: Yisheng Pan
Date: 2026-01
"""

import os
import sys
import torch
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
from datetime import datetime
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, PROJECT_ROOT)

from src.models.attention_cae import AttentionCAE
from src.models.autoencoder import QuantCAE
from src.models.vision_engine import VisionEngine
from src.data.data_loader import DataLoader
from src.strategies.backtester import Backtester
from src.strategies.factor_mining import FactorMiner


class AblationStudy:
    """
    æ¶ˆèå®éªŒä¸»ç±»
    
    å®éªŒé…ç½®ï¼š
    - Baseline: æ— Attentionçš„CAE
    - w/o Attention: ç§»é™¤Attentionæ¨¡å—
    - w/o Correlation: ç§»é™¤ä»·æ ¼ç›¸å…³æ€§è¿‡æ»¤
    - w/o Time Isolation: ç§»é™¤æ—¶é—´éš”ç¦»
    - ResNet Features: ä½¿ç”¨é¢„è®­ç»ƒResNetç‰¹å¾
    - Different Heads: ä¸åŒæ³¨æ„åŠ›å¤´æ•° (4, 8, 16)
    - Different Dims: ä¸åŒç‰¹å¾ç»´åº¦ (512, 1024, 2048)
    """
    
    def __init__(self, data_dir: str = None, model_dir: str = None):
        """
        Args:
            data_dir: æ•°æ®ç›®å½•
            model_dir: æ¨¡å‹ç›®å½•
        """
        self.data_dir = data_dir or os.path.join(PROJECT_ROOT, "data")
        self.model_dir = model_dir or os.path.join(self.data_dir, "models")
        
        self.loader = DataLoader()
        self.factor_miner = FactorMiner()
        
        # å®éªŒé…ç½®
        self.configs = {
            'full_model': {
                'use_attention': True,
                'num_heads': 8,
                'latent_dim': 1024,
                'use_correlation': True,
                'correlation_threshold': 0.5,
                'use_time_isolation': True,
                'isolation_days': 20,
                'feature_extractor': 'attention_cae'
            },
            'w_o_attention': {
                'use_attention': False,
                'num_heads': 0,
                'latent_dim': 1024,
                'use_correlation': True,
                'correlation_threshold': 0.5,
                'use_time_isolation': True,
                'isolation_days': 20,
                'feature_extractor': 'cae'
            },
            'w_o_correlation': {
                'use_attention': True,
                'num_heads': 8,
                'latent_dim': 1024,
                'use_correlation': False,
                'correlation_threshold': 0.0,
                'use_time_isolation': True,
                'isolation_days': 20,
                'feature_extractor': 'attention_cae'
            },
            'w_o_time_isolation': {
                'use_attention': True,
                'num_heads': 8,
                'latent_dim': 1024,
                'use_correlation': True,
                'correlation_threshold': 0.5,
                'use_time_isolation': False,
                'isolation_days': 0,
                'feature_extractor': 'attention_cae'
            },
            'resnet_features': {
                'use_attention': False,
                'num_heads': 0,
                'latent_dim': 2048,
                'use_correlation': True,
                'correlation_threshold': 0.5,
                'use_time_isolation': True,
                'isolation_days': 20,
                'feature_extractor': 'resnet50'
            },
            'heads_4': {
                'use_attention': True,
                'num_heads': 4,
                'latent_dim': 1024,
                'use_correlation': True,
                'correlation_threshold': 0.5,
                'use_time_isolation': True,
                'isolation_days': 20,
                'feature_extractor': 'attention_cae'
            },
            'heads_16': {
                'use_attention': True,
                'num_heads': 16,
                'latent_dim': 1024,
                'use_correlation': True,
                'correlation_threshold': 0.5,
                'use_time_isolation': True,
                'isolation_days': 20,
                'feature_extractor': 'attention_cae'
            },
            'dim_512': {
                'use_attention': True,
                'num_heads': 8,
                'latent_dim': 512,
                'use_correlation': True,
                'correlation_threshold': 0.5,
                'use_time_isolation': True,
                'isolation_days': 20,
                'feature_extractor': 'attention_cae'
            },
            'dim_2048': {
                'use_attention': True,
                'num_heads': 8,
                'latent_dim': 2048,
                'use_correlation': True,
                'correlation_threshold': 0.5,
                'use_time_isolation': True,
                'isolation_days': 20,
                'feature_extractor': 'attention_cae'
            }
        }
    
    def load_model(self, config: Dict) -> torch.nn.Module:
        """
        æ ¹æ®é…ç½®åŠ è½½æ¨¡å‹
        
        Args:
            config: å®éªŒé…ç½®å­—å…¸
            
        Returns:
            åŠ è½½çš„æ¨¡å‹
        """
        feature_extractor = config['feature_extractor']
        
        if feature_extractor == 'attention_cae':
            model = AttentionCAE(
                latent_dim=config['latent_dim'],
                num_attention_heads=config['num_heads'],
                use_attention=config['use_attention']
            )
            model_path = os.path.join(self.model_dir, "attention_cae_best.pth")
            if os.path.exists(model_path):
                model.load_state_dict(torch.load(model_path, map_location='cpu'))
            return model
        
        elif feature_extractor == 'cae':
            model = QuantCAE()
            model_path = os.path.join(self.model_dir, "cae_best.pth")
            if os.path.exists(model_path):
                model.load_state_dict(torch.load(model_path, map_location='cpu'))
            return model
        
        elif feature_extractor == 'resnet50':
            import torchvision.models as models
            model = models.resnet50(pretrained=True)
            model.fc = torch.nn.Identity()  # ç§»é™¤åˆ†ç±»å¤´
            return model
        
        else:
            raise ValueError(f"Unknown feature extractor: {feature_extractor}")
    
    def run_single_experiment(
        self, 
        config_name: str, 
        config: Dict,
        test_symbols: List[str],
        start_date: str = "2023-07-01",
        end_date: str = "2025-01-01"
    ) -> Dict:
        """
        è¿è¡Œå•ä¸ªå®éªŒé…ç½®
        
        Args:
            config_name: é…ç½®åç§°
            config: é…ç½®å­—å…¸
            test_symbols: æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨
            start_date: å›æµ‹å¼€å§‹æ—¥æœŸ
            end_date: å›æµ‹ç»“æŸæ—¥æœŸ
            
        Returns:
            å®éªŒç»“æœå­—å…¸
        """
        print(f"\n{'='*60}")
        print(f"ğŸ”¬ è¿è¡Œå®éªŒ: {config_name}")
        print(f"{'='*60}")
        print(f"é…ç½®: {json.dumps(config, indent=2)}")
        
        # åŠ è½½æ¨¡å‹
        model = self.load_model(config)
        model.eval()
        
        # åˆ›å»ºVisionEngineï¼ˆéœ€è¦æ ¹æ®é…ç½®ä¿®æ”¹ï¼‰
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…éœ€è¦ä¿®æ”¹VisionEngineä»¥æ”¯æŒä¸åŒé…ç½®
        vision_engine = VisionEngine()
        
        # è¿è¡Œå›æµ‹
        results = []
        for symbol in test_symbols[:10]:  # å…ˆç”¨10åªè‚¡ç¥¨æµ‹è¯•
            try:
                # è·å–æ•°æ®
                df = self.loader.get_stock_data(symbol)
                if df.empty:
                    continue
                
                # è¿è¡Œç­–ç•¥ï¼ˆç®€åŒ–ç‰ˆï¼Œå®é™…éœ€è¦å®Œæ•´å›æµ‹é€»è¾‘ï¼‰
                # è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…éœ€è¦è°ƒç”¨å®Œæ•´çš„å›æµ‹æ¡†æ¶
                result = self._run_backtest_single_stock(
                    symbol, df, vision_engine, config, start_date, end_date
                )
                results.append(result)
                
            except Exception as e:
                print(f"âš ï¸ è‚¡ç¥¨ {symbol} å›æµ‹å¤±è´¥: {e}")
                continue
        
        # æ±‡æ€»ç»“æœ
        if not results:
            return None
        
        summary = self._summarize_results(results, config_name)
        return summary
    
    def _run_backtest_single_stock(
        self,
        symbol: str,
        df: pd.DataFrame,
        vision_engine: VisionEngine,
        config: Dict,
        start_date: str,
        end_date: str
    ) -> Dict:
        """
        å•åªè‚¡ç¥¨çš„å›æµ‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
        
        å®é™…å®ç°éœ€è¦ï¼š
        1. æ ¹æ®configä¿®æ”¹vision_engineçš„æœç´¢é€»è¾‘
        2. åº”ç”¨ç›¸å…³æ€§è¿‡æ»¤å’Œæ—¶é—´éš”ç¦»
        3. è®¡ç®—æ”¶ç›Š
        """
        # è¿™é‡Œæ˜¯å ä½ç¬¦ï¼Œå®é™…éœ€è¦å®Œæ•´çš„å›æµ‹é€»è¾‘
        return {
            'symbol': symbol,
            'return': np.random.uniform(-0.2, 0.4),  # å ä½ç¬¦
            'sharpe': np.random.uniform(0.5, 2.0),  # å ä½ç¬¦
            'max_drawdown': np.random.uniform(-0.3, -0.1),  # å ä½ç¬¦
            'win_rate': np.random.uniform(0.4, 0.7)  # å ä½ç¬¦
        }
    
    def _summarize_results(self, results: List[Dict], config_name: str) -> Dict:
        """
        æ±‡æ€»å®éªŒç»“æœ
        """
        returns = [r['return'] for r in results]
        sharpes = [r['sharpe'] for r in results]
        max_dds = [r['max_drawdown'] for r in results]
        win_rates = [r['win_rate'] for r in results]
        
        return {
            'config_name': config_name,
            'num_stocks': len(results),
            'avg_return': np.mean(returns),
            'std_return': np.std(returns),
            'avg_sharpe': np.mean(sharpes),
            'avg_max_dd': np.mean(max_dds),
            'avg_win_rate': np.mean(win_rates),
            'returns': returns,
            'sharpes': sharpes
        }
    
    def run_all_experiments(
        self,
        test_symbols: List[str] = None,
        start_date: str = "2023-07-01",
        end_date: str = "2025-01-01"
    ) -> pd.DataFrame:
        """
        è¿è¡Œæ‰€æœ‰æ¶ˆèå®éªŒ
        
        Args:
            test_symbols: æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨ï¼ˆNoneåˆ™ä½¿ç”¨é»˜è®¤ï¼‰
            start_date: å›æµ‹å¼€å§‹æ—¥æœŸ
            end_date: å›æµ‹ç»“æŸæ—¥æœŸ
            
        Returns:
            ç»“æœDataFrame
        """
        if test_symbols is None:
            # é»˜è®¤æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨
            test_symbols = [
                '000001', '000002', '600000', '600036', '600519',
                '600887', '000858', '002415', '300059', '601318'
            ]
        
        all_results = []
        
        for config_name, config in self.configs.items():
            result = self.run_single_experiment(
                config_name, config, test_symbols, start_date, end_date
            )
            if result:
                all_results.append(result)
        
        # è½¬æ¢ä¸ºDataFrame
        df_results = pd.DataFrame(all_results)
        
        # è®¡ç®—ç›¸å¯¹äºFull Modelçš„å·®å¼‚
        if 'full_model' in df_results['config_name'].values:
            full_model_metrics = df_results[df_results['config_name'] == 'full_model'].iloc[0]
            df_results['delta_return'] = df_results['avg_return'] - full_model_metrics['avg_return']
            df_results['delta_sharpe'] = df_results['avg_sharpe'] - full_model_metrics['avg_sharpe']
        
        return df_results
    
    def generate_latex_table(self, df_results: pd.DataFrame, output_path: str = None) -> str:
        """
        ç”ŸæˆLaTeXæ ¼å¼çš„ç»“æœè¡¨æ ¼
        
        Args:
            df_results: å®éªŒç»“æœDataFrame
            output_path: è¾“å‡ºè·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            LaTeXè¡¨æ ¼å­—ç¬¦ä¸²
        """
        # é‡å‘½åé…ç½®åç§°ä»¥ä¾¿æ˜¾ç¤º
        name_map = {
            'full_model': 'Full Model (VQ)',
            'w_o_attention': 'w/o Attention',
            'w_o_correlation': 'w/o Correlation',
            'w_o_time_isolation': 'w/o Time Isolation',
            'resnet_features': 'ResNet Features',
            'heads_4': 'Heads=4',
            'heads_16': 'Heads=16',
            'dim_512': 'Dim=512',
            'dim_2048': 'Dim=2048'
        }
        
        df_display = df_results.copy()
        df_display['config_name'] = df_display['config_name'].map(name_map)
        
        latex = "\\begin{table}[t]\n"
        latex += "\\centering\n"
        latex += "\\caption{Ablation Study Results}\n"
        latex += "\\label{tab:ablation}\n"
        latex += "\\begin{tabular}{lcccc}\n"
        latex += "\\toprule\n"
        latex += "Configuration & Return & Alpha & Sharpe & $\\Delta$Alpha \\\\\n"
        latex += "\\midrule\n"
        
        for _, row in df_display.iterrows():
            config = row['config_name']
            ret = row['avg_return'] * 100
            alpha = row.get('delta_return', 0) * 100
            sharpe = row['avg_sharpe']
            
            latex += f"{config} & {ret:.1f}\\% & {alpha:+.1f}\\% & {sharpe:.2f} & {alpha:+.1f}\\% \\\\\n"
        
        latex += "\\bottomrule\n"
        latex += "\\end{tabular}\n"
        latex += "\\end{table}\n"
        
        if output_path:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(latex)
        
        return latex


def main():
    """
    ä¸»å‡½æ•°ï¼šè¿è¡Œæ¶ˆèå®éªŒ
    """
    print("="*60)
    print("ğŸ”¬ VisionQuant æ¶ˆèå®éªŒ")
    print("="*60)
    
    study = AblationStudy()
    
    # è¿è¡Œæ‰€æœ‰å®éªŒ
    df_results = study.run_all_experiments()
    
    # ä¿å­˜ç»“æœ
    output_dir = os.path.join(PROJECT_ROOT, "logs")
    os.makedirs(output_dir, exist_ok=True)
    
    csv_path = os.path.join(output_dir, "ablation_results.csv")
    df_results.to_csv(csv_path, index=False)
    print(f"\nâœ… ç»“æœå·²ä¿å­˜: {csv_path}")
    
    # ç”ŸæˆLaTeXè¡¨æ ¼
    latex_path = os.path.join(output_dir, "ablation_table.tex")
    latex_table = study.generate_latex_table(df_results, latex_path)
    print(f"âœ… LaTeXè¡¨æ ¼å·²ä¿å­˜: {latex_path}")
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*60)
    print("ğŸ“Š å®éªŒç»“æœæ±‡æ€»")
    print("="*60)
    print(df_results[['config_name', 'avg_return', 'avg_sharpe', 'delta_return']].to_string())
    
    return df_results


if __name__ == "__main__":
    main()
