import akshare as ak
import pandas as pd
import os
import time
import logging
from tqdm import tqdm
from datetime import datetime, timedelta
from typing import Optional

# === è·¯å¾„é…ç½® ===
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(os.path.dirname(CURRENT_DIR))
DATA_RAW_DIR = os.path.join(PROJECT_ROOT, "data", "raw")

# æ—¥å¿—ï¼ˆä¸å¼ºè¡Œè¦†ç›–å…¨å±€ logging é…ç½®ï¼Œäº¤ç”±å…¥å£å¤„ç»Ÿä¸€é…ç½®ï¼‰
logger = logging.getLogger(__name__)

# å¯¼å…¥æ•°æ®æºé€‚é…å™¨
from .data_source import DataSource, AkshareDataSource
from .jqdata_adapter import JQDataAdapter
from .rqdata_adapter import RQDataAdapter
from .quality_checker import DataQualityChecker


class DataLoader:
    """
    æ•°æ®åŠ è½½å™¨ï¼ˆæ”¯æŒå¤šæ•°æ®æºåˆ‡æ¢ï¼‰
    
    æ”¯æŒçš„æ•°æ®æºï¼š
    - 'akshare': å…è´¹æ•°æ®æºï¼ˆé»˜è®¤ï¼‰
    - 'jqdata': èšå®½æ•°æ®æºï¼ˆéœ€è¦è®¤è¯ï¼‰
    - 'rqdata': ç±³ç­æ•°æ®æºï¼ˆéœ€è¦è®¤è¯ï¼‰
    """
    
    def __init__(self, data_source: str = 'akshare', **kwargs):
        """
        åˆå§‹åŒ–æ•°æ®åŠ è½½å™¨
        
        Args:
            data_source: æ•°æ®æºåç§° ('akshare', 'jqdata', 'rqdata')
            **kwargs: æ•°æ®æºç‰¹å®šå‚æ•°
                - å¯¹äºjqdata: username, password
                - å¯¹äºrqdata: username, password
        """
        if not os.path.exists(DATA_RAW_DIR):
            os.makedirs(DATA_RAW_DIR)
        self.data_dir = DATA_RAW_DIR
        
        # åˆå§‹åŒ–æ•°æ®æº
        self.data_source_name = data_source
        self.data_source = self._init_data_source(data_source, **kwargs)
        
        # åˆå§‹åŒ–æ•°æ®è´¨é‡æ£€æŸ¥å™¨
        self.quality_checker = DataQualityChecker()
        self.enable_quality_check = kwargs.get('enable_quality_check', True)
    
    def _init_data_source(self, source_name: str, **kwargs) -> DataSource:
        """
        åˆå§‹åŒ–æ•°æ®æº
        
        Args:
            source_name: æ•°æ®æºåç§°
            **kwargs: æ•°æ®æºå‚æ•°
            
        Returns:
            DataSourceå®ä¾‹
        """
        if source_name == 'akshare':
            return AkshareDataSource()
        elif source_name == 'jqdata':
            username = kwargs.get('username') or kwargs.get('jq_username')
            password = kwargs.get('password') or kwargs.get('jq_password')
            return JQDataAdapter(username=username, password=password)
        elif source_name == 'rqdata':
            username = kwargs.get('username') or kwargs.get('rq_username')
            password = kwargs.get('password') or kwargs.get('rq_password')
            return RQDataAdapter(username=username, password=password)
        else:
            logger.warning("æœªçŸ¥æ•°æ®æº: %sï¼Œä½¿ç”¨ akshare ä½œä¸ºé»˜è®¤", source_name)
            return AkshareDataSource()
    
    def switch_data_source(self, source_name: str, **kwargs):
        """
        åˆ‡æ¢æ•°æ®æº
        
        Args:
            source_name: æ–°æ•°æ®æºåç§°
            **kwargs: æ•°æ®æºå‚æ•°
        """
        self.data_source_name = source_name
        self.data_source = self._init_data_source(source_name, **kwargs)
        logger.info("å·²åˆ‡æ¢åˆ°æ•°æ®æº: %s", source_name)
    
    def get_current_data_source(self) -> str:
        """è·å–å½“å‰æ•°æ®æºåç§°"""
        return self.data_source_name

    def get_stock_data(self, symbol, start_date="20200101", end_date=None, adjust="qfq", use_cache=True):
        """
        [æ™ºèƒ½æ›´æ–°ç‰ˆ] è·å–è‚¡ç¥¨æ•°æ®ï¼ˆæ”¯æŒå¤šæ•°æ®æºï¼‰
        
        é€»è¾‘ï¼š
        1. å¦‚æœuse_cache=Trueï¼Œå…ˆæ£€æŸ¥æœ¬åœ°ç¼“å­˜
        2. å¦‚æœæ•°æ®æ»åæˆ–ä¸å­˜åœ¨ï¼Œä»å½“å‰æ•°æ®æºä¸‹è½½
        3. å¦‚æœå½“å‰æ•°æ®æºä¸å¯ç”¨ï¼Œå›é€€åˆ°akshare
        
        Args:
            symbol: è‚¡ç¥¨ä»£ç 
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            adjust: å¤æƒç±»å‹
            use_cache: æ˜¯å¦ä½¿ç”¨æœ¬åœ°ç¼“å­˜
        """
        if end_date is None:
            end_date = datetime.now().strftime("%Y%m%d")

        symbol = str(symbol).strip().zfill(6)
        file_path = os.path.join(self.data_dir, f"{symbol}.csv")

        need_download = False
        df = pd.DataFrame()

        # === 1. æ£€æŸ¥æœ¬åœ°ç¼“å­˜ï¼ˆå¦‚æœå¯ç”¨ï¼‰ ===
        if use_cache and os.path.exists(file_path):
            try:
                df = pd.read_csv(file_path, index_col=0, parse_dates=True)
                if not df.empty:
                    last_date_in_file = df.index[-1].date()
                    today = datetime.now().date()
                    
                    if last_date_in_file < today:
                        need_download = True
                    else:
                        return df  # æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œç›´æ¥è¿”å›
                else:
                    need_download = True
            except Exception as e:
                logger.warning("è¯»å–æœ¬åœ°ç¼“å­˜å¤±è´¥ %s (%s): %s", symbol, file_path, e)
                need_download = True
        else:
            need_download = True

        # === 2. ä»æ•°æ®æºä¸‹è½½ï¼ˆå¦‚æœéœ€è¦ï¼‰ ===
        if need_download:
            # å°è¯•ä»å½“å‰æ•°æ®æºè·å–
            if self.data_source and self.data_source.is_available():
                print(f"â¬‡ï¸ [{self.data_source_name}] æ­£åœ¨æ‹‰å– {symbol} æœ€æ–°è¡Œæƒ…...")
                df_new = self.data_source.get_stock_data(
                    symbol=symbol,
                    start_date=start_date,
                    end_date=end_date,
                    adjust=adjust
                )
                
                if df_new is not None and not df_new.empty:
                    # æ•°æ®è´¨é‡æ£€æŸ¥
                    if self.enable_quality_check:
                        quality_result = self.quality_checker.check_data_quality(df_new, symbol)
                        if not quality_result['is_valid']:
                            print(f"âš ï¸ [{symbol}] æ•°æ®è´¨é‡æ£€æŸ¥æœªé€šè¿‡ (å¾—åˆ†: {quality_result['score']}/100)")
                            if quality_result['score'] < 50:
                                print(f"  é”™è¯¯: {quality_result['errors']}")
                                # è´¨é‡å¤ªå·®ï¼šä¼˜å…ˆä½¿ç”¨æ—§æ•°æ®ï¼›æ²¡æœ‰æ—§æ•°æ®åˆ™ç»§ç»­èµ°å›é€€æ•°æ®æºé€»è¾‘
                                if not df.empty:
                                    return df  # è¿”å›æ—§æ•°æ®
                                df_new = None  # è§¦å‘å›é€€
                    
                    # è´¨é‡ä¸é€šè¿‡ä¸”æ²¡æœ‰æ—§æ•°æ®ï¼šç»§ç»­èµ°å›é€€ï¼Œä¸åœ¨æ­¤å¤„ä¿å­˜/è¿”å›
                    if df_new is not None and not df_new.empty:
                        # ä¿å­˜åˆ°æœ¬åœ°ç¼“å­˜
                        if use_cache:
                            df_new.to_csv(file_path)
                        return self._normalize_columns(df_new)
                else:
                    print(f"âš ï¸ [{self.data_source_name}] è·å–æ•°æ®å¤±è´¥ï¼Œå°è¯•å›é€€...")
            
            # å›é€€åˆ°akshareï¼ˆå¦‚æœå½“å‰ä¸æ˜¯akshareï¼‰
            if self.data_source_name != 'akshare':
                print(f"ğŸ”„ å›é€€åˆ°akshareæ•°æ®æº...")
                fallback_source = AkshareDataSource()
                if fallback_source.is_available():
                    df_new = fallback_source.get_stock_data(
                        symbol=symbol,
                        start_date=start_date,
                        end_date=end_date,
                        adjust=adjust
                    )
                    if df_new is not None and not df_new.empty:
                        if use_cache:
                            df_new.to_csv(file_path)
                        return self._normalize_columns(df_new)
            
            # å¦‚æœæ‰€æœ‰æ•°æ®æºéƒ½å¤±è´¥ï¼Œè¿”å›æ—§æ•°æ®ï¼ˆå¦‚æœæœ‰ï¼‰
            if not df.empty:
                print(f"âš ï¸ æ‰€æœ‰æ•°æ®æºè·å–å¤±è´¥ï¼Œä½¿ç”¨æœ¬åœ°æ—§æ•°æ®")
                return self._normalize_columns(df)
            
            return pd.DataFrame()

        return self._normalize_columns(df)

    def _normalize_columns(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ç»Ÿä¸€å¸¸è§åˆ—åï¼Œä¿è¯ä¸‹æ¸¸é‡ä»·ç‰¹å¾å¯ç¨³å®šè·å–
        """
        if df is None or df.empty:
            return df
        data = df.copy()
        col_map = {}
        for c in data.columns:
            lc = str(c).lower()
            if lc in ["open", "å¼€ç›˜"]:
                col_map[c] = "Open"
            elif lc in ["high", "æœ€é«˜"]:
                col_map[c] = "High"
            elif lc in ["low", "æœ€ä½"]:
                col_map[c] = "Low"
            elif lc in ["close", "æ”¶ç›˜", "æ”¶ç›˜ä»·"]:
                col_map[c] = "Close"
            elif lc in ["volume", "æˆäº¤é‡"]:
                col_map[c] = "Volume"
            elif lc in ["amount", "æˆäº¤é¢", "æˆäº¤é‡‘é¢", "æˆäº¤é¢(å…ƒ)"]:
                col_map[c] = "Amount"
            elif lc in ["turnover", "æ¢æ‰‹ç‡", "æ¢æ‰‹"]:
                col_map[c] = "Turnover"
        if col_map:
            data = data.rename(columns=col_map)
        return data

    def get_top300_stocks(self):
        """è·å–å…¨Aè‚¡åˆ—è¡¨å¹¶æŒ‰å¸‚å€¼æ’åº"""
        # ä¼˜å…ˆä½¿ç”¨å½“å‰æ•°æ®æº
        if self.data_source and self.data_source.is_available():
            try:
                stock_list = self.data_source.get_stock_list()
                if not stock_list.empty:
                    # å¦‚æœæœ‰å¸‚å€¼ä¿¡æ¯ï¼ŒæŒ‰å¸‚å€¼æ’åº
                    if 'market_cap' in stock_list.columns:
                        stock_list = stock_list.sort_values(by='market_cap', ascending=False)
                    return stock_list.head(300)
            except Exception as e:
                print(f"âš ï¸ [{self.data_source_name}] è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
        
        # å›é€€åˆ°akshare
        try:
            df = ak.stock_zh_a_spot_em()
            if 'æ€»å¸‚å€¼' in df.columns:
                df = df.sort_values(by='æ€»å¸‚å€¼', ascending=False)
            df = df.head(300)
            return df[['ä»£ç ', 'åç§°']].rename(columns={'ä»£ç ': 'code', 'åç§°': 'name'})
        except Exception as e:
            print(f"âŒ è·å–åå•å¤±è´¥: {e}")
            return pd.DataFrame()

    def download_batch_data(self, stock_list, start_date="20200101"):
        """æ‰¹é‡ä¸‹è½½"""
        print(f"â¬‡ï¸ [æ‰¹é‡ç»´æŠ¤] æ­£åœ¨æ£€æŸ¥å¹¶æ›´æ–° {len(stock_list)} åªè‚¡ç¥¨...")
        for _, row in tqdm(stock_list.iterrows(), total=len(stock_list)):
            symbol = str(row['code']).zfill(6)
            self.get_stock_data(symbol, start_date=start_date)
            # ç¨å¾®å¿«ä¸€ç‚¹ï¼Œå› ä¸ºå¤§éƒ¨åˆ†å¯èƒ½ä¸éœ€è¦ä¸‹è½½
            time.sleep(0.01)


if __name__ == "__main__":
    loader = DataLoader()
    # æµ‹è¯•æ›´æ–°é€»è¾‘
    df = loader.get_stock_data("601899")
    print(f"æœ€æ–°æ•°æ®æ—¥æœŸ: {df.index[-1]}")