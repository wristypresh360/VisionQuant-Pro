"""
ç”¨ AttentionCAE é‡å»º FAISS ç´¢å¼•

è¿™ä¸ªè„šæœ¬ä¼šï¼š
1. åŠ è½½è®­ç»ƒå¥½çš„ AttentionCAE æ¨¡å‹
2. æ‰«ææ‰€æœ‰ K çº¿å›¾ï¼ˆ40ä¸‡å¼ ï¼‰
3. ç”¨æ–°æ¨¡å‹é‡æ–°ç¼–ç æ‰€æœ‰å›¾ç‰‡
4. æ„å»ºæ–°çš„ FAISS ç´¢å¼•

è¿è¡Œæ—¶é—´ï¼šçº¦ 1-2 å°æ—¶ï¼ˆå–å†³äº CPU/GPUï¼‰
"""

import os
import sys
import argparse
import torch
import torch.nn as nn
from torchvision import transforms
from PIL import Image
import faiss
import pandas as pd
import numpy as np
from tqdm import tqdm
from datetime import datetime
import glob

# === è·¯å¾„é…ç½® ===
CURRENT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(CURRENT_DIR)
if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)

from src.models.attention_cae import AttentionCAE

# è¾“å…¥è¾“å‡ºè·¯å¾„ï¼ˆé»˜è®¤å€¼ï¼Œå¯è¢«å‘½ä»¤è¡Œè¦†ç›–ï¼‰
DEFAULT_IMG_BASE_DIR = os.path.join(PROJECT_ROOT, "data", "images")
MODEL_PATH = os.path.join(PROJECT_ROOT, "data", "models", "attention_cae_best.pth")
DEFAULT_INDEX_FILE = os.path.join(PROJECT_ROOT, "data", "indices", "cae_faiss_attention.bin")
DEFAULT_META_CSV = os.path.join(PROJECT_ROOT, "data", "indices", "meta_data_attention.csv")

parser = argparse.ArgumentParser(description="ç”¨ AttentionCAE é‡å»º FAISS ç´¢å¼•")
parser.add_argument("--img-dir", type=str, default=DEFAULT_IMG_BASE_DIR, help="Kçº¿å›¾ç›®å½•ï¼ˆé»˜è®¤ data/imagesï¼‰")
parser.add_argument("--index-file", type=str, default=DEFAULT_INDEX_FILE, help="è¾“å‡ºç´¢å¼•æ–‡ä»¶è·¯å¾„")
parser.add_argument("--meta-csv", type=str, default=DEFAULT_META_CSV, help="è¾“å‡ºå…ƒæ•°æ®CSVè·¯å¾„")
args = parser.parse_args()

IMG_BASE_DIR = args.img_dir
INDEX_FILE = args.index_file
META_CSV = args.meta_csv

# è®¾å¤‡é€‰æ‹©
if torch.backends.mps.is_available():
    device = torch.device("mps")
    print("ğŸš€ ä½¿ç”¨ Apple MPS GPU åŠ é€Ÿ")
elif torch.cuda.is_available():
    device = torch.device("cuda")
    print("ğŸš€ ä½¿ç”¨ CUDA GPU åŠ é€Ÿ")
else:
    device = torch.device("cpu")
    print("ğŸ’» ä½¿ç”¨ CPUï¼ˆè¾ƒæ…¢ï¼Œå»ºè®®ç”¨ GPUï¼‰")

# === 1. åŠ è½½æ¨¡å‹ ===
print("\n" + "="*60)
print("ğŸ“¦ æ­¥éª¤ 1: åŠ è½½ AttentionCAE æ¨¡å‹")
print("="*60)

model = AttentionCAE(latent_dim=1024, num_attention_heads=8).to(device)
if os.path.exists(MODEL_PATH):
    state_dict = torch.load(MODEL_PATH, map_location=device)
    model.load_state_dict(state_dict)
    model.eval()
    print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {MODEL_PATH}")
else:
    print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {MODEL_PATH}")
    sys.exit(1)

# é¢„å¤„ç†
preprocess = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
])

# === 2. æ‰«ææ‰€æœ‰å›¾ç‰‡ ===
print("\n" + "="*60)
print("ğŸ“‚ æ­¥éª¤ 2: æ‰«æ K çº¿å›¾ç›®å½•")
print("="*60)

# æŸ¥æ‰¾æ‰€æœ‰ PNG æ–‡ä»¶
all_img_paths = glob.glob(os.path.join(IMG_BASE_DIR, "**", "*.png"), recursive=True)
print(f"âœ… æ‰¾åˆ° {len(all_img_paths)} å¼ å›¾ç‰‡ (ç›®å½•: {IMG_BASE_DIR})")

if len(all_img_paths) == 0:
    print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼è¯·æ£€æŸ¥è·¯å¾„:", IMG_BASE_DIR)
    sys.exit(1)

# === 3. æå–ç‰¹å¾å‘é‡ ===
print("\n" + "="*60)
print("ğŸ” æ­¥éª¤ 3: ç”¨ AttentionCAE ç¼–ç æ‰€æœ‰å›¾ç‰‡")
print("="*60)
print("âš ï¸  è¿™å¯èƒ½éœ€è¦ 1-2 å°æ—¶ï¼Œè¯·è€å¿ƒç­‰å¾…...")

features_list = []
meta_list = []
batch_size = 32  # æ‰¹å¤„ç†å¤§å°

# åˆ›å»ºè¾“å‡ºç›®å½•
os.makedirs(os.path.dirname(INDEX_FILE), exist_ok=True)

with torch.no_grad():
    for i, img_path in enumerate(tqdm(all_img_paths, desc="ç¼–ç ä¸­")):
        try:
            # åŠ è½½å›¾ç‰‡
            img = Image.open(img_path).convert('RGB')
            input_tensor = preprocess(img).unsqueeze(0).to(device)
            
            # ç¼–ç ï¼ˆAttentionCAE.encode() è¿”å› 1024 ç»´ï¼Œå·² L2 å½’ä¸€åŒ–ï¼‰
            feature = model.encode(input_tensor)
            feature_np = feature.cpu().numpy().flatten().astype('float32')
            
            features_list.append(feature_np)
            
            # ä»è·¯å¾„æå–è‚¡ç¥¨ä»£ç å’Œæ—¥æœŸ
            # è·¯å¾„æ ¼å¼: data/images/600519/600519_20230101.png
            filename = os.path.basename(img_path)
            parts = filename.replace('.png', '').split('_')
            if len(parts) >= 2:
                symbol = parts[0].zfill(6)
                date_str = parts[1]
            else:
                # å¤‡ç”¨è§£æ
                symbol = os.path.basename(os.path.dirname(img_path)).zfill(6)
                date_str = filename.replace('.png', '')
            
            meta_list.append({
                'symbol': symbol,
                'date': date_str,
                'path': img_path
            })
            
        except Exception as e:
            print(f"\nâš ï¸  è·³è¿‡æŸåå›¾ç‰‡ {img_path}: {e}")
            continue

print(f"\nâœ… ç¼–ç å®Œæˆï¼å…±å¤„ç† {len(features_list)} å¼ å›¾ç‰‡")

# === 4. æ„å»º FAISS ç´¢å¼• ===
print("\n" + "="*60)
print("ğŸ”¨ æ­¥éª¤ 4: æ„å»º FAISS ç´¢å¼•")
print("="*60)

features_array = np.array(features_list)
dim = features_array.shape[1]
print(f"ç‰¹å¾ç»´åº¦: {dim} (åº”è¯¥æ˜¯ 1024)")

# åˆ›å»ºç´¢å¼•ï¼ˆä½¿ç”¨å†…ç§¯ï¼Œå› ä¸ºç‰¹å¾å·² L2 å½’ä¸€åŒ–ï¼‰
index = faiss.IndexFlatIP(dim)

# å½’ä¸€åŒ–ï¼ˆç¡®ä¿æ˜¯å•ä½å‘é‡ï¼‰
faiss.normalize_L2(features_array)

# æ·»åŠ å‘é‡
print("æ­£åœ¨æ·»åŠ å‘é‡åˆ°ç´¢å¼•...")
index.add(features_array)

print(f"âœ… ç´¢å¼•æ„å»ºå®Œæˆï¼åŒ…å« {index.ntotal} æ¡è®°å½•")

# === 5. ä¿å­˜ç´¢å¼•å’Œå…ƒæ•°æ® ===
print("\n" + "="*60)
print("ğŸ’¾ æ­¥éª¤ 5: ä¿å­˜ç´¢å¼•å’Œå…ƒæ•°æ®")
print("="*60)

# ä¿å­˜ FAISS ç´¢å¼•
faiss.write_index(index, INDEX_FILE)
print(f"âœ… FAISS ç´¢å¼•å·²ä¿å­˜: {INDEX_FILE}")

# ä¿å­˜å…ƒæ•°æ® CSV
meta_df = pd.DataFrame(meta_list)
meta_df.to_csv(META_CSV, index=False)
print(f"âœ… å…ƒæ•°æ®å·²ä¿å­˜: {META_CSV}")

# === 6. æ›´æ–° VisionEngine é…ç½® ===
print("\n" + "="*60)
print("ğŸ“ æ­¥éª¤ 6: æ›´æ–°é…ç½®")
print("="*60)
print("âš ï¸  è¯·æ‰‹åŠ¨æ›´æ–° src/models/vision_engine.py ä¸­çš„ç´¢å¼•è·¯å¾„ï¼š")
print(f"   INDEX_FILE = '{INDEX_FILE}'")
print(f"   META_CSV = '{META_CSV}'")
print("\næˆ–è€…ç›´æ¥æ›¿æ¢æ—§ç´¢å¼•æ–‡ä»¶ï¼ˆå¤‡ä»½åï¼‰ï¼š")
print(f"   mv {INDEX_FILE} {os.path.join(PROJECT_ROOT, 'data', 'indices', 'cae_faiss.bin')}")
print(f"   mv {META_CSV} {os.path.join(PROJECT_ROOT, 'data', 'indices', 'meta_data.csv')}")

print("\n" + "="*60)
print("ğŸ‰ ç´¢å¼•é‡å»ºå®Œæˆï¼")
print("="*60)
print(f"æ€»è®°å½•æ•°: {index.ntotal}")
print(f"ç‰¹å¾ç»´åº¦: {dim}")
print(f"ç´¢å¼•æ–‡ä»¶: {INDEX_FILE}")
print(f"å…ƒæ•°æ®æ–‡ä»¶: {META_CSV}")
